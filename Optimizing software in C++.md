
# 1 简介

本手册适用那些想要是软件更快的编程人员和软件开发者.本手册假设读者熟练掌握C++编程语言,并了解编译器是如何工作的.至于选择C++作为本手册基础的原因,将在稍后解释.

本手册的内容基于笔者对编译器和微处理器是如何工作的研究.本手册中的建议是针对x86家族的微处理器,包括intel,AMD 和 VIA的处理器(包括64位版本).x86处理器是Widows, Linux, BSD 和 Mac OS X中使用最多的平台,虽然这些操作系统也可以适用其他微处理器,当然很多设备也使用其他平台和变异语言.

本手册是一个系列五本手册中的第一本:
    1. Optimizing software in C++:An optimization guide for Windows,Linux adn Mac.
    2. Optimizing subroutines in assembly languague:An optimization guide for x86 platforms.
    3. The microarchitecture of Intel,AMD and VIA CPUs:An optimization guide for assembly programmers and compiler makers.
    4. Instruction tables:Lists of instruction latencies,throughputs and micro-operation breakdowns for Intel, AMD and VIA CPUs.
    5. Calling conventions for dirrerent C++ compilers and operating systems.

 这些手册的最新版本可以在[www.anger.org/optimize](www.anger.org/optimize),版权声明将列在手册的最后面.

只用高级语言编写软件的读者只需要阅读本书即可.后续的内容是为了那些想要深入了解 指令集,汇编语言和编译器,处理器微架构的读者准备的.更高层次的优化可以通过使用汇编(for CPU-intensive code?)而获得,这将会在后续的内容中进一步讨论.

请注意到有非常多的人使用到我的优化手册.因此我不可能有时间回答每一个人的问题.所以请不要将你的编程问题发送给我,因为你将得不到任何答案.建议初学者在提高自己的编程经验后,再来尝试手册中所提到的技术.你可以在互联网上的诸多论坛中找到你问题的答案,如果你在相关书籍和手册中找不到答案的话.

我想要感谢那些给我的优化手册发送修正和建议的人,我总是很高兴能够收到相关信息.

## 1.1 优化的代价

如今大学的编程课程在软件开发过程中强调结构化、面向对象、模块化、可重用性、系统化。但是这些要求通常都和优化软件的速度呵呵大小相冲突。

如今，软件导师更经常建议我们函数或者方法的行数应该尽可能的少。但是在几十年前，建议通常是相反的：如果某些功能只会调用一次，那么不要就不要把他们封装在分离的子程序中。软件编写风格的建议变化，是是为软件项目变的越来越大、越来越复杂，需要将注意力集中在软件开发中，而且电脑的性能也越来越强大。

软件结构化开发的高优先级和程序性能的低优先级，首先反映在编程语言和接口框架的选择上。这对于最终的用户来说，这通常是一个缺点，他们不得不购买性能更加强大的计算机，来跟上更大的软件包，即使对于简单的任务，响应时间也长的不能接受，这使得他们感到沮丧。

有时候为了使软件更小更快，有必要在软件开发的高级原则上妥协。本手册讨论了如何在这些要求之间取得合理的平衡。讨论了如何识别和隔离程序中的最关键部分，并将优化工作集中在该部分。讨论了在相对原始的编程风格中，如何克服不自动检查数组越界，无效指针等。讨论了在哪些高级编程结构需要更多的执行时间，哪些需要更少的执行时间。


# 2 选择最优平台

## 2.1 硬件平台的选择

硬件平台的选择相对于过去来说，变成的更不重要了。RISC（精简指令集）和CISC（复杂指令集）处理器、PC和大型主机（mainframes）以及简单处理器（simple processors）和向量处理器（vector processors）之间的区别，变得越来越模糊。拥有CISC指令集的标准PC处理器也包括了RISC核心、向量处理指令（vector processing instruction）、多核、超过以前大型主机的处理速度。

现如今，对于确定任务的硬件平台的选择通常是由诸如价格、兼容性、第二选择（sencond source）和可用的好的开发工具等因素而不是处理能力决定的。在一个网路中连接几个标准PC可能比投资一个大型主机更便宜、更有效率。具有大规模并行向量处理能力的大型超级计算机在科学计算中人有一席之地，但是对于大多数目的来说，标准PC处理器还是首选，应为它们具有更高的性价比。

从技术角度来看，标准PC处理器的的CISC指令集（也称为x86）不是最佳的。这个指令集还在维护，是为了兼容那些在70年代的软件，而当时RAM和硬盘空间是非常稀缺的资源。然而，CISC指令集实际上要比它的名声要好。紧凑的代码使得缓存的效率在缓存资源依旧非常有限的今天更加高效。CISC指令集实际上在缓存资源非常有限的时候比RISC指令集更好。x86指令集最糟糕的问题是缺少寄存器。这个问题在x86指令集的64位扩展中得到了缓解，其中寄存器的数量翻了一倍。

由于无法控制网络资源的响应时间，对于关键的应用程序，不建议使用依赖网络资源的瘦客户机（Thin clients）。

小型手持设备正变得越来越受欢迎，并被用于越来越多的用途，如电子邮件、浏览网页，这些在以前都需要使用一台PC。类似的，我们正看到有越来越多的设备和机器采用嵌入式处理器。我对使用哪些平台和操作系统更高效，没有任具体的建议。但我们需要认识到这些设备通常情况下，内存和计算能力都是要少于PC的，这一点非常重要。因此在这样的系统上节约资源使用比在PC平台上更加重要。然而，通过良好的软件设计，即使在这样的小型设备上，许多应用程序也可以获得良好的表现，这些将在17章进行讨论。

本手册继续标准的PC平台，采用Intel、AMD或者VIA处理器，使用Windows、Linux、BSD或者MAC操作系统。这里给出的很多建议也适用于其它平台，但是都只在PC平台上通过测试。

### 图形加速器

平台的选择明显受任务要求的影响。例如，较大的图形应用编程序最好在具有图形协处理器或者图形加速卡的平台上实现。一些系统也有专门的物理处理器来处理游戏或者动画中的物理运动。

在某些情况下，可以将图形加速卡的高处理能力用于除了图形渲染之外的其他用途。然而，这样的应用具有非常高的系统依赖性。因此如果可移植性非常重要的话，就不推荐这么做。本手册将不会讨论图形处理器。

### 可编程逻辑器件

可编程逻辑器件是一种可以使用硬件描述语言（如VHDL、Verilog）进行编程的芯片。常见的有CPLD和FPGA。编程语言（例如C++）和硬件描述语言的区别是：编程语言定义了一个一系列指令的算法，而硬件描述语言定义了由例如*门*、*触发器*、*多路复用器*、*算术单元*等原件和连接它们的导线组成的硬件电路。硬件描述语言天生就是并行的，因为它定义的是电气连接而不是一系列操作序列。

对于一个复杂的数字操作，可编程逻辑器件通常比微处理器中处理的更快，因为硬件可以特定的目的连接。

在FPGA中实现微处理器作为所谓的软核（soft processor）是可能的。然而这样的处理通常比专用微处理器慢的多，因此它本身并没有什么优势。但是在某些情况下，使用硬件描述语言在同一芯片中定义的软核，执行某些关键应用中的特定指令，是一个非常有效的解决方案。当然将专用微处理器和FPGA集成在同一个芯片中是一个更加强大额解决方案。像这样的混合解决方案已经在一些嵌入式系统中被采用了。

我认为这样类似的解决方案，会有一天在PC处理器中采用。应用程序将可以定义由硬件描述语言编码的应用程序专用指令。这样的处理器除了代码缓存和数据缓存外，还将会有用于硬件描述代码的缓存

## 2.2 微处理器的选择

由于激烈的竞争,不同竞品微处理器的基准性能都非常接近。多核处理器对于那些需要并行运行多个线程的应用程序来说，是好处的。而小型轻量型的低功耗处理器对于非密集型的应用来说也是相当强大的。

一些系统具有图形处理单元，无论是实在图形卡上，亦或是继承在CPU芯片中。这样的单元可以当作协处理器用于一些繁重的图形计算。在某些情况下，也可以将图形处理单元的计算能力用于其它目的，而不是设计它的目的。一些系统还有一个物理处理单元用于计算电脑游戏中物体的运动。

## 2.3 操作系统的选择

x86家族中，所有较新的处理都可以在16-bit、32-bit以及64-bit模式下运行。

16-bit模式在较早的操作系统 *DOS*和*Windows 3.x*中使用。如果程序或者数据的大小超过64 kbytes，这些系统将使用内存分割。这是非常低效率的。现代微处理器没有针对16-bit模式进行优化，一些系统也没有向后兼容16-bit的程序。除了小型嵌入式系统，是不建议编写16-bit程序的。

如今（2013年）32-bit和64-bit的操作系统非常常见，它们在性能上也没有很大的区别。65-bit软件并没有很大的市场，但可以确定的是64-bit系统将主宰未来。

对于一些具很多函数调用和大量使用CPU资源的应用程序来说，可以提升5-10%的性能。如果性能瓶颈在其它地方，32-bit系统和64-bit系统并没有区别。当然使用大量内存的应用程序可以得益于64-bit系统大地址空间。

软件开发者可以在两个版本中选择需要消耗大量内存的软件：为了与现有系统的兼容的32-bit版本，以及具有最佳性能的64-bit版本。

对于32-bit软件，*Windows操作系统*和*Linux操作系统*的性能几乎相当，因为这两个系统使用同样的函数调用约定（*function calling conventions*）。*FreeBSD*和*Open BSD*在软件优化上，几乎所有方面都是相同的。这里说关于*Linux*的所有建议，同样适用于*BSD 系统*。

基于*Intel*的*Mac OS X操作系统*实在*BSD*的基础上开发的，但是编译器默认使用*位置无关代码*（*position-independent code*）和*延迟绑定*，这会降低它的效率。可以通过使用*静态连接*和关闭*位置无关代码*（选项：**-fno-pic**)，来提升性能。

相对于32-bit系统，64-bit系统具有以下几个优点：
1. 两倍的寄存器数量。这样可以在寄存器中而不是内存中存储中间数据和局部变量。
2. 函数参数使用寄存器传递，而不是使用堆栈，这使得函数调用额效率更高。
3. 整数寄存器扩展到64 bits。这样的唯一好处是，应用程序可以使用64位整数。
4. 大内存的分配和释放的效率更高。
5. 所有的64位 CPU和操作系统都支持*SSE2*指令集。
6. 64-bit指令集支持数据的自相关寻址，这使得*位置无关代码*的效率更高。

相对于32-bit系统，64-bit系统具有以下几个缺点：
1. 指针、引用和堆栈入口使用64 bits而不是32 bits，这导致数据缓存的效率更低。
2. 在64 bit模式下，如果装载地址不能保证小于2<sup>31</sup>, 访问静态或者全局数组将会需要几个额外的指令来计算地址。这些额外的成本在64位的Windows和Mac程序中可以看到，但是在Linux中很少见。
3. 在大内存模型（代码和数据的大小超过2 Gbytes）中，地址的计算将更加的复杂。虽然这种大内存模型很少能用到。
4. 一些指令的长度，64-bit模式下的长度要比32-bit模式下要长1字节。
5. 一些64位编译器要不如它们的32位版本。

总的来说，如果程序有很多函数调用、大量大内存快的分配、或者可以利用64位整数的优势，那么你可以期待64位程序会比32位程序跑的略微快一点。当程序使用超过2 gigabytes的数据时，就非常有必要使用64位的系统了。

当在64位模式下运行时，操作系统之间的相似性将会消失，因为函数的调用约定时不同的。64位的*Windows*只允许4个函数参数通过寄存器传递，而64位的*Linux*、*BSD*、*Mac*允许通过寄存器传递14个参数（6个整数和8个浮点数）。还有其他的细节使得64位*Linux*的函数调用比64位*Windows*的效率更高（详见第五册**Calling conventions for different compilers and operating systems**）。一个具有很多函数调用的的程序，有可能在64位的*Linux*上，比在64位的*Windows*运行的更快。64位*Windows* 的这个缺点可以通关是关键函数为内联的或者静态的，或者通过使用可以使进行这个程序优化的编译器来减轻。

## 2.4 编程语言的选择

在开始一个新的软件项目之前，决定哪种编程语言最适合手上的项目是非常重要的。低级语言有利于优化程序执行速度，而高级语言则有利于开发出清晰和结构良好的代码，以及快速和容易的开发用户界面，利用网络资源和数据库的接口等。

最终应用程序的效率取决于编程语言是如何实现的。当代码被编程并翻译成二进制可以行代码时，效率最高。**C++**、**Pascal**以及**Fortran**的绝大多数实现都是通过编译器的。

其它一些编程语言通过解释器实现。代码按原样分发（distribute），运行时逐行解释。例如*JavaScript*、*PHP*、*ASP*以及*UNIX shell script*。解释代码是是非常没有效率的，因为循环的每一次迭代，被一次又一次的解释位一个循环的主体。

有些是通过即时编译（*just-in-time compilation*）实现的。程序代码按照原样存储，一边编译一边执行，例如*Perl*。

一些现代编程语言使用一种中间代码（*byte code*，字节码），源码被编程成中间代码，这是分发的代码。中间代码不能按照原样立即执行，在执行之前，它必须经过第二步的解释或者编译。*Java*的一些实现基于解释器，解释器通过模拟所谓的Jave虚拟机来解释中间代码。最好的Jave虚拟机对于代码的最常用部分使用即时编译。*C#*、*托管C++*以及MicroSoft .Net FrameWork的一些其它一些语言都是基于中间代码的即时编译。

使用中间代码的原因在为了独立于平台且紧凑。使用中间代码的最大缺点是：为了解释或者编译中间代码，用户必须安装庞大的*runtime framework*。而这个*framework*通常需要使用比代码本身多的多的资源。中间代码的另一个是：它增加了额外的抽象层，这使得更加具体的优化更加困难。另一方面，即时编译器可以针对它所运行的CPU进行专门的优化，而在预编译代码中进行特定的优化择更加复杂。

编程语言及其实现的历史揭示了一个曲折的过程，反映了效率、平台独立性和易于开发的等相关冲突的考量。例如，第一台PC有一个*Basic*的解释器，而由于*Basic*解释器实在太慢了，很快就有了*Basic*编译器。如今，最受欢迎的*Basic*版本，是基于中间代码和即时编译的*Visual Basic .NET*。一些早期的*Pascal*实现使用类似今天*Java*的中间代码，但从有了真正的可用的编译器后，该语言获得了显著的欢迎。

从本文的讨论中可以清楚的看到，编程语言的选择需要在效率、可移植性和开发时间等原因进行妥协。当效率很重要的时候，解释类编程语言就不再考虑范围内。而当可移植性和易于开发比速度更重要时，基于中间代码和即使编译的语言可能是一种可行的这种方案。这包括*C#*、*Visual Basic*以及最好的*Java*实现。然而，这些语言的缺点时运行时框非常庞大，而每次运行程序时都必须加载该框架。加载框架和编译程序的时间有可能比执行程序所要的时间还长。而且运行时框架所消耗的资源可能比运行程序本身还多。程序使用这样的框架，对于简单的任务例如按下按钮或者移动鼠标，优势会有难以接受的长响应时间。当速度很关键时就应该避免使用*.Net framework*。

毫无疑问，使用完全编译的代码可以获得最快的执行速度。编译语言包括*C*、*C++*、*D*、*Pascal*、*Fortan*以及其它几种非著名语言。由于一些原因，我更喜欢*C++*。一些非常好的编译器和优化的函数库都支持*C++*。*C++*是一种高级的高级语言（advancd high-level language），具有其他语言中少见的丰富的高级特性。但是*C++*还将低级的*C*语言作为一个自己，因此可以进行低层次的优化。但多数*C++*编译器都支持生成汇编语言，这对于检查编译器对代码的优化成都非常有用。此外，但多数C++编译器允许类似会汇编的函数指令、内联汇编或者易于链接汇编语言模块，但需要最高级别的优化是必要的。*C++*编译器存在于所有主流平台，在这个意义上，*C++*语言是可移植的。*Pascal*相对于*C++*具有很多优势。但是不是很通用。*Fortran*也相当有效率，但是语法相当的过时。

由于有强大的开发工具可用，*C++*开发非常高效。Microsoft Visual Studio是一种非常流行的开发工具。这个工具可以实现*C++*的两种不同实现，直接编译和基于*.NET framework*公共语言运行时的中间代码。显然，当速度很重要时，直接编译的版本更受青睐。

*C++*的一个重要缺点与安全性相关。它没有对数组越界、整数溢出以及无效指针的检查。这些检查的缺席使得代码执行的比那些拥有这些检查的编程语言更快。由于程序规则无法排除这些错误情况，这使得程序员有责任对这些错误进行显示的检查。后面将会有关于这些检查的指导。

当性能优化具有很高优先级时，*C++*绝对时首选的编程语言。与其他编程语言相比，性能上的提升是相当可观的。当性能对最终的用户很重要时，这种性能上的提升，可以很容易证明在开发时间上可能会有细微的提高。

由于其他一些原因，可能需要基于中间代码的高级框架，但是部分代码仍需要仔细优化。在这种情况下，混合实现可能是一个可行的解决档案。代码中最重要的部分可以由基于编译的*C++*或者汇编语言实现，而剩余的部分包括用户界面等，可以使用高级框架实现。被优化的代码部分可以被编译位动态链接库（*DLL*），供其他代码调用。这不是一个最佳的解决档案，因为高级框架任然消耗大量的资源，而这两种代码之间的转换也会产生额外耗费CPU时间的消耗。但是当对时间要求高的部分可以完全包含在DLL中时，这种解决方案也可以显著的提高性能。

另一个值得考虑的选择时*D语言*。*D语言*具有*Java*和*C++*的许多特性，同时避免了很多*C++*的缺点。而且，*D语言*编译成的二进制代码可以与*C*或者*C++*代码链接在译器，但是*D语言*的IDS和编译器没有*C++*的好。

## 2.5 编译器的选择

市面上有几种不同的*C++*编译器可供选择。很难预测哪一个编译器对于一段特定的代码可以做到最佳的优化。每一个编译器都会做一些非常聪明和非常愚蠢的事情。下面将列举一些常见的编译器。
能都非常接近。多核处理器对于那些需要并行运
### Microsoft Visual Studio
这是一个非常友好的编译器，具有许多特性。完整的版本非常昂贵，但是有限制的非商业版本是免费的。Visual Studio可以为. Net框架构建代码，也可以直接编译代码(编译时不使用公共语言运行时，CLR，生成二进制代码)。支持32位和64位 Windows。集成开发环境(IDE)支持多种编程语言的分析和调试。支持多核处理的OpenMP指令。Visual Studio的优化相当好，但它不是最好的优化器。

### Borland/CodeGear/Embarcadero C++ builder
它的IDE具有很多和VS相同的特性，只支持32位 Windows。不支持最新的指令集。优化做的没有Microsoft、Intel 和Gnu的编译器好。

### Intel C++ compiler (parallel composer)
*Intel*编译器没有它自己的IDE。它可以作为VS和Eclipse的插件。当使用命令行或者make工具时，它也可以作为一个独立的编译器。支持32位和64位 的*Windows*和*Linux*，也支持基于Intel的*Mac OS* 和 *Itaniumx系统*。Intel编译器支持向量指令、自动矢量化、OpenMP和自动并行化。支持CPU调度，为不同的CPU生成不同版本的代码。在所有的平台上，对于内联汇编都有非常好的支持，使得在*Windows*和*Linux*上使用相同的内联汇编语法成为可能。编译还提供了一些具有最佳优化的数学函数库。

*Intel*编译器最重要的缺点是：它编译的代码在*AMD*和*VIA*的处理器上运行的较慢或者根本不运行。可以通过绕过所谓的CPU调度机制来避免这个问题,该调度机制检查代码是否运行在*Intel CPU*  上。

就从代码可以从它众多的优化特性中受益和可以移植到众多平台上的来说，*Intel*编译器是一个很好额选择。

### Gnu
虽然缺少用户友好，但这是可以使用的最佳编译器之一。它是免费并且开源的。它支持大多数*Linux*发行版本、*BSD*、*Mac OS X*，无论是32位的还是64位的。支持OpenMP、自动并行化和自动矢量化。Gnu的函数库至今还没有完全优化过。同时支持*AMD*和*Intel*的向量数学库（vector math libraries)。*Gnu C++*编译器在众多的平台上可用，包括32位和64位的*Linux*、*BSD*、*Windows*以及*Mac*。对于所有的平台来说*Gnu*编译器都是一个非常不错的选择。它是使用命令行运行的独立编译器，但是可以用于很多IDE，包括*Eclipse*、*NetBeans*、*CodeBlocks*和*BloodShed*。

### Clang
*Clang*编译器基于*LLVM*（Low Level Virtual Machine）。它和*Gnu*编译器在很多方面都相似，并与*Gnu*编译器高度兼容。这是*Mac*平台上最常用的编译器，也支持*Linux*和*Windows*平台。对于所有的平台*Clang*编译器都是一个不错的选择。它可以和*Eclipse IDE*一起使用。

### PGI
该编译器支持32位和64位的*Windows*、*Linux*和*Mac*。之前并行编程、OpenMP和自动矢量化。优化相当不错。但是向量指令的效率很低。

### 7.Digital Mars
这是一个便宜的编译器，用于32位 *Windows*，包含IDE。优化的不是很好。

### Open Watcom
另一个32位的Windows开源编译器。默认情况下不符合标准的调用约定，优化合理。

### Codeplay VectorC
一个32位的Windows商业编译器。集成到Microsoft Visual Studio IDE中。显然已经不再更新了。可以做自动矢量化。优化适度。支持三种不同的目标文件格式。

### 总结
在没有IDE的情况下，所有这些编译器都可以作为命令行版本使用。商业编译器有免费的试用版本提供。

在*Linux*平台上，通常可以混合来自不同编译器的目标文件（*Object File*），在某些情况下，也可以在Windows平台上也可以。*Microsoft*和*Intel*的Windows编译器在目标文件级别上完全兼容，而*Digital Mars*编译器基本上与它们兼容。*Embarcadero*、*Codeplay*和*Watcom*编译器在目标文件级别上与其他编译器不兼容。

为了良好的代码性能，我建议在Unix应用程序中使用Gnu、Clang或Intel编译器，在Windows应用程序中使用Gnu、Clang、Intel或Microsoft编译器。如果您希望您的代码在AMD微处理器上高效运行，请不要使用Intel编译器。

编译器的选择可能在某些情况下由遗留代码兼容的要求，IDE具体的参数选择，调试工具，简单的GUI开，数据库集成web应用程序集成，混合语言编程等决定。如果所选择的编译器不提供最好的优化，在这种情况下，最关键的模块使用不同的编译器可能是非常有帮助的。在大多数情况下，如果包含必要的库文件，那么由*Intel*编译器生成的目标文件可以毫无问题地链接到使用*Microsoft*或*Gnu*编译器生成的项目中。或者，使用最好的编译器生成DLL，并从使用另一个编译器构建的项目中调用它。





## 2.6 函数库的选择

有些应用程序将大部分执行时间花在执行库函数上。Tim-econsuming库函数通常属于以下类别之一：
1. 文件输入/输出
2. 图形和声音处理
3. 内存和字符串操作
4. 数学函数
5. 加密，解密和数据压缩

大多数编译器都包含用于这些目的的标准库。不幸的是，标准库并不总是完全优化的。

库函数通常是许多用户在许多不同应用程序中使用的一小段代码。因此，与优化特定于应用程序的代码相比，值得在优化库函数方面投入更多的精力。最好的函数库是使用*汇编语言*和*自动cpu调度* 以及最新的*指令集扩展*高度优化的。

如果分析显示库函数在某个特定应用程序占用了大量CPU时间，或者如果这是显而易见的，那么可以通过使用不同的函数库来显著提高性能。如果应用程序在库函数中花费了大部分时间，那么除了寻找最有效的库和节省库函数调用之外，可能不需要优化其他任何地方。建议尝试不同的库，看看哪个最好。

下面将讨论一些常见的函数库。还有许多用于特殊目的的库。

### Microsoft
微软编译器自带。有些函数优化得很好，有些则没有。支持32位和64位 *Windows*。

### Borland / CodeGear / Embarcadero
*Borland C++ builder*自带。未针对*SSE2*和后续指令集进行优化。只支持32位 *Windows*。

### Gnu
*Gnu*编译器自带的。没有像编译器本身优化的好。64位版本比32位版本好。Gnu编译器经常插入内置代码，而不是最常见的内存和字符串指令。内置代码不是最优的。使用选项*-fno-builtin*使用库版本替代内置版本。*Gnu*库支持32位和64位*Linux*和*BSD*。Windows版本目前还不是最新的。

### Mac
*Mac OS X* （*Darwin*）* Gnu*编译器中包含的库是*Xnu*项目的一部分。在所谓的**commpage**中，操作系统内核中包含了一些最重要的函数。这些功能针对*Intel Core*和稍后的*Intel*处理器版本进行了高度优化。*AMD*处理器和早期的英特尔处理器根本不被支持。只能在Mac平台上运行。

### Intel
*Intel*编译器包含标准函数库。还有一些特殊用途的库，如“*Intel Math Kernel Library*”和“*"ntegrated Performance Primitives*”。这些函数库针对大型数据集进行了高度优化。然而，英特尔的库在AMD和VIA处理器上并不能总是运行良好。有关解释和可能的解决方法，请参见后面的章节。支持所有x86和x86-64平台。

### AMD
*AMD*数学核心库包含优化的数学函数。它也适用于英特尔处理器。性能不如*Intel*库。支持32位和64位*Windows*和*Linux*。

### AsmLib
我自己的函数库是为了演示而创建的。可以从[www.agner.org/optimize/asmlib.zip](www.agner.org/optimize/asmlib.zip)获得。目前包括内存和字符串函数的优化版本，以及其他一些很难在其他地方找到的函数。在最新的处理器上运行时，比大多数其他库都要快。支持所有x86和x86-64平台。

<center>

|                  Test                  |   Processor    | Microsoft | CodeGear | Intel | Mac  | Gnu <br> 32-bits</br> | Gnu <br>32-bits</br>-fno-builtin | Gnu <br>64-bits</br>-fno-builtin | Asmlib |
| :------------------------------------: | :------------: | :-------: | :------: | :---: | :--: | --------------------- | -------------------------------- | -------------------------------- | ------ |
| `memcpy`16kB <br>aligned operands</br> |  Intel Core 2  |   0.12    |   0.18   | 0.12  | 0.11 | 0.18                  | 0.18                             | 0.18                             | 0.11   |
|  `memcpy`16kB <br>unaligned op.</br>   |  Intel Core 2  |   0.63    |   0.75   | 0.18  | 0.11 | 1.21                  | 0.57                             | 0.44                             | 0.12   |
| `memcpy`16kB <br>aligned operands</br> | AMD Opteron K8 |   0.24    |   0.25   | 0.24  | n.a. | 1.00                  | 0.25                             | 0.28                             | 0.22   |
|  `memcpy`16kB <br>unaligned op.</br>   | AMD Opteron K8 |   0.38    |   0.44   | 0.40  | n.a. | 1.00                  | 0.35                             | 0.29                             | 0.28   |
|           `strlen`128 bytes            |  Intel Core 2  |   0.77    |   0.89   | 0.40  | 0.30 | 4.5                   | 0.82                             | 0.59                             | 0.27   |
|           `strlen`128 bytes            | AMD Opteron K8 |   1.09    |   1.25   | 1.61  | n.a. | 2.23                  | 0.95                             | 0.6                              | 1.19   |


表2.1. 不同函数库性能对比
</center>
表中的数字是每字节数据的核心时钟周期(低数字意味着良好的性能)。对齐的操作数意味着源和目标的地址都可以被16整除。
<u>用于测试库的版本（不是最新的）</u>
* Microsoft Visual studio 2008, v. 9.0
* CodeGear Borland bcc, v. 5.5
* Mac: Darwin8 g++ v 4.0.1.
* Asmlib: v. 2.00
* Intel C++ compiler, v. 10.1.020.  使用库*libircmt.lib* 中的 `_intel_fast_memcpy` 和 `__intel_new_strlen`函数。函数名没有文档。

## 2.7 用户界面框架的选择

典型软件项目中的大多数代码都进入用户界面。不需要大量计算的应用程序很可能在用户界面上花费的CPU时间比在程序的基本任务上花费的还要多。

程序员很少从头开始编写自己的图形用户界面。这不仅浪费了程序员的时间，也给最终用户带来了不便。出于可用性的考虑，菜单、按钮、对话框等应该尽可能地标准化。程序员可以使用操作系统附带的标准用户界面元素或编译器和开发工具附带的库。

*Microsoft Foundation Classes*是一个流行的*Windows*  *C++*用户界面库(**MFC**)。与之竞争的产品是Borland现已停止继续维护的*Object  Windows Library*（**OWL**）。*Linux*系统有几个可用的图形界面框架。用户界面库可以作为运行时DLL或静态库链接。除非多个应用程序同时使用同一个DLL，运行时DLL比静态库占用更多的内存资源。

 用户界面库可能比应用程序本身更大，需要更多的时间来加载。一个轻量级的替代方案是*Windows Template Library*（**WTL**）。*WTL*应用程序通常比*MFC*应用程序更快、更紧凑。由于糟糕的文档、缺乏高级开发工具，WTL应用程序可能会花费更多的时间去开发。

通过放弃使用图形用户界面并使用控制台模式程序，可以获得最简单的用户界面。控制台模式程序的输入通常在命令行或输入文件中指定。输出到控制台或文件。控制台模式的程序是快速、紧凑和易于开发的。方便移植到不同的平台，因为它不依赖于系统特定的图形界面调用。可用性可能很差，因为它缺少图形用户界面的自解释菜单。控制台模式程序对于从其他应用程序(如实现工具库)调用非常有用。

结论是，用户界面框架的选择必须是开发时间、可用性、程序紧凑性和运行时间之间的折衷。没有一个通用的解决方案对所有应用程序都是最好的。

## 2.8 克服C++语言的缺点

虽然c++在优化方面有很多优点，但它也有一些缺点，这使得开发人员不得不选择其他编程语言。本节将讨论在选择*C++*进行优化时如何克服这些缺点。

### <u>可移植性</u>
===
c++是完全可移植的，因为它的语法在所有主要平台上都是完全标准化和受支持的。然而，c++也是一种允许直接访问硬件接口和系统调用的语言。这些当然是系统特有的。为了方便在平台之间进行移植，建议将用户界面代码和其他系统特定部分放在一个单独的模块中，并将代码的任务特定部分(应该是系统独立的)放在另一个模块中。

整数的大小和其他硬件相关细节取决于硬件平台和操作系统。详情见第29页（TODO）。

### <u>开发时间</u>
===
一些开发人员认为特定的编程语言和开发工具比其他语言和开发工具使用起来更快。虽然有些区别仅仅是习惯的问题，但确实有些开发工具具有强大的功能，可以自动完成许多琐碎的编程工作。通过一致的模块化和可重用类，可以降低C++项目的开发时间并提高可维护性。

### <u>安全性</u>
===
*C++*语言最严重的问题与安全性有关。标准*C++*的实现没有检查数组边界违规和无效指针。这是*C++*程序中常见的错误来源，也是黑客可能的攻击点。有必要遵守某些编程原则，以防止在涉及安全性的程序中出现此类错误。

无效指针的问题可以通过使用引用代替指针，通过初始化指针为0，通过将指针指向的对象无效时将指针设置为0来避免，还可以通过避免指针算术和指针类型转换来避免。通常使用指针的链表和其他数据结构可以使用更高效的容器类模板替代，如第95页（TODO：）所述。避免使用`scanf`函数。

数组越界可能是*C++*程序错误的最常见原因。对数组边界外的赋值操作，可能会重写其他变量，更糟糕的是，它可能会重写定义数组的函数的返回地址。这会导致各种奇怪和意想不到的行为。数组通常用作存储文本或输入数据的缓冲区。缺少对输入数据缓冲区溢出的检查是黑客经常利用的一个常见错误。

防止此类错误的一个好方法是使用经过良好测试的容器类来替换数组。标准模板库（**STL**）是此类容器类的一个有用来源。不幸的是，许多标准容器类以一种低效的方式来使用动态内存分配。有关如何避免动态内存分配的示例，请参见第92页（TODO：）。有关高效容器类的讨论，请参见第95页（TODO：）。[www.agner.org/optimize/cppexamples.zip](www.agner.org/optimize/cppexamples.zip)上本手册的附录含带有边界检查和各种高效容器类的数组示例。

文本字符串尤其有问题，因为字符串的长度可能没有特定的限制。在字符数组中存储字符串的旧式*C*风格方法快速有效，但不安全，除非在存储之前检查每个字符串的长度。这个问题的标准解决方案是使用*string*类，例如**string**或**CString**。这是安全且灵活的，但在大型应用程序中效率非常低。每次创建或修改字符串时，string类都会分配一个新的内存块。这可能会导致内存碎片化，并涉及堆管理和垃圾收集的高开销成本。一个不影响安全性的更有效的解决方案是将所有字符串存储在一个内存池中。有关如何在内存池中存储字符串，请参见附录中的示例（[参见www.agner.org/optimize/cppexamples.zip](www.agner.org/optimize/cppexamples.zip)）。

整数溢出是另一个安全问题。官方的*C*标准说，在溢出的情况下，有符号整数的行为是“未定义的”。这允许编译器忽略溢出或假设它没有发生。在*Gnu*编译器的情况下，不发生带符号整数溢出的假设的不幸后果是，它允许编译器优化掉溢出检查。对于这个问题，有许多可能的补救措施：（1）在溢出前进行，（2）使用无符号整数——它们是保证回绕（*wrap around*），（3）使用选项`-ftrapv`捕获整数溢出,但这是非常低效的，（4）使用选项`-Wstrict-overflow = 2`，对这样的优化进行警告，(5)使用选项`-fwrapv`或`-fno-strict-overflow`明确定义溢出行为。

在代码中速度很重要的关键部分，您可能会偏离上述安全建议。如果不安全的代码仅限于经过良好测试的函数、类、模板或模块，并且与程序的其余部分有良好定义的接口，那么这是被允许的。


# 3 找到消耗时间最多的地方

## 3.1 一个时钟周期是多少？
在本手册中，我使用CPU时钟周期而不是秒或微秒作为时间度量单位。这是因为不同计算机有不同的速度。今天，如果我写下某事需要10μs,那么在下一代的电脑，它可能只需要5μs，而我的手册将很快被淘汰。但是如果我写下某事需要10个时钟周期，即使CPU时钟频率加倍，那么它仍然需要10个时钟周期。

时钟周期的长度是时钟频率的倒数。例如，如果时钟频率是2 GHz，那么时钟周期的长度是：

<center>

```mathjax
$$
\frac {1} {2GHz}=5ns
$$
```
</center>

一台计算机上的时钟周期并不总是可以与另一台计算机上的时钟周期相比较。奔腾4 （*NetBurst*） CPU的被设计为具有比其他CPU更高的时钟频率，但是总的来说，在执行同一段代码时，它比其他CPU耗费更多的时钟周期。

假设程序中的一个循环重复1000次，循环中有100个浮点运算（加法、乘法等）。如果每个浮点运算需要5个时钟周期,然后我们可以大致估计,循环将1000 * 100 * 5 * 0.5 ns = 250μs 2 GHz CPU。我们应该尝试优化这个循环吗?当然不！250μs小于1/50的时间刷新屏幕。用户不可能看到延迟。但是在这个循环中还存在另一个循环，另一个循环也重复1000次，那么我们估计计算时间为250毫秒。这种延迟的时间足够长，足以引起注意，但也不够长，足以令人厌烦。我们可能决定做一些测量，看看我们的估计是否正确，或者计算时间是否实际超过250毫秒。如果响应时间太长，用户实际上必须等待结果，那么我们将考虑是否有可以改进的地方。

## 3.2 使用分析器查找热点（*hot spots*）
在开始优化任何东西之前，必须先识别程序的关键部分。在一些程序中，超过99%的时间花在最内部的循环中进行数学计算。在其他程序中，99%的时间花在读取和写入数据文件上，只有不到1%的时间花在实际操作这些数据上。优化重要部分的代码，而不是优化只占总时间的一小部分代码，这一点非常重要。优化代码中不太重要的部分不仅会浪费时间，还会使代码不太清晰，更难于调试和维护。

大多数编译器包都包含一个分析器，它可以告诉每个函数被调用的次数和时间。也有第三方剖析器，如*AQtime*、*Intel VTune*和*AMD CodeAnalyst*。

有几种不同的分析方法:
* 植入：编译器在每次函数调用时插入额外的代码，以计算调用函数的次数和时间。
* 调试：分析器在每个函数或每一行代码中插入临时调试断点。
* 基于时间的采样：分析器告诉操作系统生成一个中断，例如每毫秒一次。分析器计算在程序的每个部分中发生中断的次数。这不需要修改被测程序，但可靠性较差。
* 基于事件的采样：分析器告诉CPU在某些事件上生成中断，例如每次发生1000次缓存丢失。这使得查看程序的哪个部分有最多的缓存丢失、分支错误预测、浮点异常等等成为可能。基于事件的采样需要基于CPU的分析其。对于Intel CPU使用*Intel VTune*，对于AMD CPU使用*AMD CodeAnalyst*。

不幸的是，分析器通常是不可靠的。它们有时会给出误导的结果，或者完全因为技术问题而失败。分析器的一些常见问题是：
* 粗糙的时间测量。如果时间是以毫秒级的分辨率测量的，并且关键函数的执行需要几微秒，那么测量可能变得不精确，或者干脆为零。
* 执行时间过短或过长。如果被测程序在短时间内完成，那么采样生成的数据太少，无法进行分析。如果程序执行时间太长，那么采样生成的数据太多，超出分析器的分析能力。
* 等待用户输入。许多程序将大部分时间用于等待用户输入或网络资源。这个时间包含在分析文件中。为了使分析可行，可能需要修改程序以使用一组测试数据而不是用户输入。
* 来自其他过程的干扰。分析器不仅测量被测试程序中所花费的时间，而且还测量在同一台计算机上运行的所有其他进程（包括分析器本身）所使用的时间。
* 函数地址在优化的程序中是模糊的。分析器通过地址识别程序中的任何热点，并尝试将这些地址转换为函数名。但是，高度优化的程序经常以这样一种方式重新组织:函数名和代码地址之间没有明确的对应关系。内联函数的名称对于分析器可能根本不可见。其结果将是关于哪些功能花费的时间最多的误导性报告。
* 使用调试版本的代码。一些分析器要求您正在测试的代码包含调试信息，以便识别单个函数或代码函数。代码的调试版本没有优化。
* 在CPU内核之间跳转。进程或线程不一定停留在多核CPU上的同一处理器内核中，但事件计数器可以。这导致在多个CPU内核之间跳转的线程的事件计数没有意义。您可能需要通过设置线程关联掩码将线程锁定到特定的CPU内核。
* 再现性不好。程序执行中的延迟可能是由不可重现的随机事件引起的。诸如任务切换和垃圾收集之类的事件可以在随机时间发生，这使得程序的某些部分看起来比正常情况下花费的时间更长。

有多种方法可以替代分析器。一个简单的替代方法是在调试器中运行程序，并在程序运行时按下**break**。如果有一个热点，占用90%的CPU时间，那么中断有90%的机会发生在这个热点。重复中断几次可能足以确定一个热点。在调试器中使用调用堆栈来识别热点周围的情况。

有时，识别性能瓶颈的最佳方法是将度量工具直接放入代码中，而不是使用现成的分析器。这并不能解决与概要分析相关的所有问题，但通常会提供更可靠的结果。如果您不满意分析器的工作方式，那么您可以将所需的测量仪器插入程序本身。您可以添加计数器变量来计算程序的每个部分执行了多少次。此外，您可以读取程序中每个最重要或关键部分前后的时间，以度量每个部分所花费的时间。有关此方法的进一步讨论，请参阅第157页（TODO）。

您的测量代码应该包含`#if`指令，以便在代码的最终版本中禁用它。在代码中插入自己的分析工具是z在程序开发过程中跟踪程序性能的一种非常有用的方法。

如果时间间隔很短，时间测量可能需要很高的分辨率。在Windows中，您可以使用`GetTickCount`或`QueryPerformanceCounter`函数获得毫秒级的分辨率。使用CPU中的时间戳计数器可以获得更高的分辨率，它以CPU时钟频率计数（在Windows中: `__rdtsc()`）。

如果线程在不同的CPU内核之间跳转，时间戳计数器将失效。在时间度量期间，您可能必须将线程固定到特定的CPU核心，以避免这种情况。（在*Windows*中是`SetThreadAffinityMask`，在*Linux*中是`sched_setaffness`)。

程序应该用一组真实的测试数据进行测试。测试数据应该具有一个典型的随机性，以便获得真实数量的缓存丢失和分支错误预测。

当发现程序中最耗时的部分时，重要的是将优化工作集中在耗时的部分上。关键代码片段可以使用第157页中（TODO）描述的方法进行进一步测试和研究。

分析器对于查找与CPU密集型代码相关的问题最有用。但是许多程序在加载文件或访问数据库、网络和其他资源时所花费的时间比算术运算要多。下面几节将讨论最常见的时间消耗器。

## 3.3 安装程序
安装程序包所需的时间通常不被认为是软件优化问题。但这肯定会占用用户的时间。如果软件优化的目标是为用户节省时间，那么安装软件包并使其正常工作所花费的时间是不能忽略的。由于现代软件的高度复杂性，安装过程花费一个多小时是很正常的。为了找到并解决兼容性问题，用户必须多次重新安装软件包，这种情况也很常见。

软件开发人员在决定软件包是否使用需要安装许多文件的复杂框架时，应该考虑安装时间和兼容性问题。安装过程应该始终使用标准化的安装工具。应该可以在开始时选择所有安装选项，以便在无人参与的情况下继续安装过程的其余部分。卸载也应该以标准化的方式进行


## 3.4 自动更新
许多软件程序通过互联网定期自动下载更新。有些程序在每次计算机启动时都会搜索更新，即使该程序从未被使用过。安装了许多这类程序的计算机需要几分钟才能启动，这完全是在浪费用户的时间。其他一些程序在每次启动时使用时间搜索更新。如果当前版本满足用户的需求，则用户可能不需要更新。搜索更新应该是可选的，默认情况下是关闭的，除非有令人信服的安全理由进行更新。更新过程应该在低优先级线程中运行，并且只有在程序实际使用时才运行。任何程序在不使用时都不应该在后台进程运行。下载的程序更新的安装应该延迟到程序关闭并重新启动。

操作系统的更新尤其耗时。有时安装操作系统的自动更新需要几个小时。这是非常有问题的，因为这些耗时的更新可能在不方便的时候出现。如果用户在离开工作场所之前出于安全原因必须关闭或注销计算机，并且系统禁止用户在更新过程中关闭计算机，那么这将是一个非常大的问题。

## 3.5 程序加载
很多时候，加载一个程序要比执行它花费更多的时间。对于基于大型运行时框架、中间代码、解释器、即时编译器等的程序，加载时间可能会非常长，这是使用*Java*, *C#*， *Visual Basic*等编程语言编写的程序的常见情况。

但是，即使是用编译的*C++*实现的程序，加载程序也会耗费时间。如果程序使用大量运行时DLL（动态链接的库或共享对象）、资源文件、配置文件、帮助文件和数据库，通常会发生这种情况。当程序启动时，操作系统可能不会加载一个大程序的所有模块。有些模块可能只在需要时加载，或者在RAM大小不足时将其交换到硬盘。

用户希望对简单的操作（如按键或鼠标移动）立即作出响应。如果因为它需要从磁盘加载模块或资源文件，这样的响应延迟了几秒钟，这对于用户来说是不可接受的。使用大量内存的应用程序会迫使操作系统将内存交换到磁盘。内存交换是鼠标移动或按键等简单操作的响应时间长得不可接受的常见原因。

避免大量的DLL，配置文件、资源文件、帮助文件等，分散再硬盘的不同地方。几个文件、最好和*.exe*文件在同一个路径下，这样是可以接受的。

## 3.6 动态链接和位置无关的代码
函数库可以是静态链接库（*\*.lib，\*.a*），或动态链接库，也称为共享对象（*\*.dll，\* . so*）。有几个因素可以使动态链接库比静态链接库慢。这些因素将在下面的149页（TODO）详细解释。

位置无关代码用于类*unix*系统中的共享对象。默认情况下，*Mac*系统在任何地方都使用与位置无关的代码。位置无关的代码效率很低，尤其是在32位模式下，原因如下面的149页所述（TODO）。


## 3.7 文件存取
读取或写入硬盘上的文件通常比处理文件中的数据花费更多的时间，特别是如果用户有一个病毒扫描程序，扫描所有访问的文件。

文件的顺序向前访问比随机访问快。读或写大块比一次读或写一小块文件更快。一次读写不要少于几千字节。你可以将整个文件复制到内存缓冲区中，并在一个操作中读写它，而不是以非顺序的方式读写几个位。通常，访问最近访问过的文件要比第一次访问快得多。这是因为文件已经复制到磁盘缓存。

远程或可移动媒体(如软盘和u盘)上的文件可能不会被缓存。这可能会产生非常戏剧性的后果。我曾经编写过一个Windows程序，该程序通过调用`WritePrivateProfileString`来创建一个文件，它每写一行就会打开和关闭一次文件。由于磁盘缓存，这在硬盘上工作得非常快，但是将文件写入软盘需要几分钟。

包含数字数据的大文件如果以二进制形式存储比以ASCII格式存储的文件更紧凑和高效。二进制数据存储的一个缺点是它不可读，并且不容易移植到具有大端存储的系统中。

在具有许多文件输入/输出操作的程序中，优化文件访问比优化CPU使用更重要。如果处理器在等待磁盘操作完成时可以执行其他工作，那么将文件访问放在一个单独的线程中可能会有好处。


## 3.8 系统数据库
在Windows中访问系统数据库可能需要几秒钟时间。与Windows系统中的大型注册数据库相比，将特定于应用程序的信息存储在单独的文件中更有效。注意，如果使用`GetPrivateProfileString`和`WritePrivateProfileString`等函数读写配置文件（*.ini文件），系统可能会将信息存储在数据库中。

## 3.9 其他数据库
许多软件应用程序使用数据库来存储用户数据。数据库会消耗大量的CPU时间、RAM和磁盘空间。在简单的情况下，可以用普通的旧数据文件替换数据库。数据库查询通常可以通过使用索引、使用集合而不是循环等方式进行优化。优化数据库查询超出了本手册的范围，但是你应该知道，优化数据库访问通常可以获得很多好处。

## 3.10 图形
图形用户界面可能使用大量的计算资源。通常会使用特定的图形框架。操作系统可以在其API中提供这样的框架。在某些情况下，在操作系统API和应用程序软件之间有一个额外的第三方图形框架层。这样一个额外的框架会消耗大量额外的资源。、

应用软件中的每个图形操作都通过调用图形库或API函数的函数调用实现的，然后这些函数调用设备驱动程序。对图形函数的调用非常耗时，因为它可能经过多个层，并且需要切换到受保护模式并再次返回。显然，对绘制整个多边形或位图的图形函数进行一次调用要比通过多次函数调用分别绘制每个像素或线条更有效率。

计算机游戏和动画中图形对象的计算当然也是很耗时的，特别是在没有图形处理单元的情况下。

各种图形函数库和驱动程序的性能差别很大。对于使用哪一种更好，我没有具体的建议。

## 3.11 其它系统资源
对打印机或其他设备的最好是一次写入大块内容，而不是每次一小块，因为对驱动程序的每次调用都涉及到切换到受保护模式并再次返回的开销。

访问系统设备和使用操作系统的高级工具可能会很耗时，因为它可能涉及到加载几个驱动程序、配置文件和系统模块。

## 3.12 访问网络
一些应用程序使用Internet或内部网络进行自动更新、远程帮助文件、数据库访问等。这里所存在的问题是访问时间无法控制。在简单的测试配置中，网络访问可能会很快，但在网络过载或用户远离服务器的使用情况下，网络访问可能很慢或完全无法访问。在决定是在本地还是远程存储帮助文件和其他资源时，这些问题应该被列入考量之中。如果需要频繁更新，那么最好在本地映射远程数据。访问远程数据库通常需要使用密码登录。对于许多辛勤工作的软件用户来说，登录过程是一个恼人的时间消耗器。在某些情况下，如果网络或数据库负载过重，登录过程可能需要一分钟以上。

## 3.13 访问内存
与对数据进行计算所需的时间相比，从RAM内存访问数据需要相当长的时间。这就是所有现代计算机都有内存缓存的原因。通常，一级数据缓存为8 - 64 Kb，二级缓存为256 Kb到2 Mb。计算机中也有可能还存在一个三级缓存。

如果程序中所有数据的总和大于二级缓存，并且分散在内存中或以非顺序方式访问，那么内存访问可能是程序中最耗时的地方。如果变量在内存缓存中，读写它只需要2-3个时钟周期，如果不缓存，则需要几百个时钟周期。参见第26页（TODO）关于数据存储，第89页（TODO）关于内存缓存。

## 3.14 上下文切换
上下文切换是多任务环境中不同任务之间的切换，多线程程序中不同线程的切换，或大型程序中的不同部分的切换。频繁的上下文切换会降低性能，因为数据缓存的内容，代码缓存、分支目标缓冲区、分支模式历史等可能需要更新。

如果分配给每个任务或线程的时间片很小，上下文切换将会更频繁。时间片的长度由操作系统决定，而不是由应用程序。

在具有多个CPU或具有多核CPU的计算机中，上下文切换的数量更少。

## 3.15 依赖链
现代微处理器可以乱序执行。这意味着如果软件指定A和B的计算，而A的计算速度较慢，则微处理器可以在计算完A之前开始计算B。显然，这只有在计算B不需要A的值时才有可能。

为了利用乱序执行的优势，必须避免长依赖链。依赖链是一系列的计算，其中每个计算依赖于前一个计算的结果。这可以妨碍CPU同时执行多个计算或者导致混乱。有关如何打破依赖关系链的示例，请参见第105页（TODO）。

## 3.16 执行单元的吞吐量
延迟和执行单元的吞吐量之间有一个重要的区别。例如，在现代CPU上执行浮点加法可能需要3-5个时钟周期。但每个时钟周期可以开始一个新的浮点加法。这意味着，如果每个加法依赖于前一个加法的结果，那么每三个时钟周期只有一个加法。但是，如果所有的加法都是独立的，那么每个时钟周期可以有一个加法。

在计算密集型的程序中，如果没有上面提到的耗时代码占主导地位，并且没有很长的依赖链，则可能获得最高的性能。在这种情况下，性能受到执行单元吞吐量的限制，而不是延迟或内存访问的限制。

现代微处理器的执行核心分为几个执行单元。通常，有两个或多个整数单元、一个或两个浮点加法单元和一个或两个浮点乘法单元。这意味着可以同时进行整数加法、浮点加法和浮点乘法。

因此，进行浮点运算的代码最好能够平衡加法和乘法。减法和加法使用相同的执行单位。除法需要更长的时间。在浮点操作之间执行整数操作而不降低性能是可能的，因为整数操作使用不同的执行单元。例如，执行浮点运算的循环通常使用整数运算来递增循环计数器、比较循环计数器与其极限等。在大多数情况下，可以假设这些整数操作不会增加总计算时间。

# 4 性能和可用性
更好的软件产品是可以为用户节省时间的产品。对于许多计算机用户来说，时间是一种宝贵的资源，许多时间浪费在速度慢、难于使用、不兼容或容易出错的软件上。所有这些问题都是可用性问题，我认为应该从更广泛的可用性角度来看待软件性能。

这不是一本关于可用性的手册，但是我认为有必要在这里引起软件编程人员注意一下影响软件使用效率的常见障碍。有关这个主题的更多信息，请参见我在Wikibooks上提供的免费电子书[Usability for Nerds](https://en.wikibooks.org/wiki/Usability_for_Nerds)。

下面的列表指出了一些让软件用户感到沮丧和浪费时间的典型原因，以及软件开发人员应该注意的一些重要的可用性问题。

1. 大型的运行时框架。*.NET*框架和*Java*虚拟机框架通常比它们运行的程序占用更多的资源。这些框架是资源问题和兼容性问题的常见来源，它们在框架本身的安装过程中、在框架下运行的程序的安装过程中、在程序启动过程中以及在程序运行过程中都会浪费大量时间。使用这种运行时框架的主要原因是为了跨平台的可移植性。不幸的是，跨平台兼容性并不总是如预期的那么好。我相信通过更好地标准化编程语言、操作系统和API，可以更有效地实现可移植性。

2. 内存交换。软件开发人员通常拥有比最终用户拥有更多RAM的功能更强大的计算机。因此，开发人员可能看不到过多的内存交换和其他资源问题，对于最终用户，这些问题导致使用大量资源的应用程序表现很差。

3. 安装问题。程序的安装和卸载过程应该标准化，由操作系统而不是由单独的安装工具来完成。

4. 自动更新。如果网络不稳定或新版本有旧版本中不存在的问题，则软件的自动更新可能会导致问题。更新机制经常会弹出一些烦人的弹出消息，比如请安装这个重要的新更新，或者告诉用户在忙于重要工作时重启计算机。更新机制不应该中断用户，而应该只显示一个独立的图标，表示更新的可用性，或者在计算机重新启动时自动更新。软件分销商经常滥用更新机制来宣传其软件的新版本。这对用户来说很烦人。

5. 兼容性问题。所有软件都应该在不同的平台、不同的屏幕分辨率、不同的系统颜色设置和不同的用户访问权限上进行测试。软件应该使用标准的API调用，而不是自定义的hack（？）和直接的访问硬件。应该使用现成的协议和标准化的文件格式。Web系统应该在不同的浏览器、不同的平台、不同的屏幕分辨率等环境中进行测试。应遵守可访问性指南。

6. 复制保护。一些复制保护方案是基于违反或规避操作系统标准的黑客攻击。这种方案是兼容性问题和系统崩溃的常见根源。许多复制保护方案都是基于硬件识别的。当硬件更新时，这种方案会导致问题。大多数的复制保护方案都让用户感到厌烦，并且阻止合法备份复制而没有组织非法的复制。应该权衡复制保护方案的好处和在可用性和必要支持上付出的成本。

7. 硬件更新。更改硬盘或其他硬件通常要求重新安装所有软件，并且还会丢失用户设置。花上整个工作日或者更多时间重新安装的情况也很常见。许多软件应用程序需要更好的备份功能，当前的操作系统需要更好的硬盘复制支持。

8.  安全。具有网络访问权限的软件易受病毒攻击和其他滥用的弱点，可能使用户付出极其昂贵的代价。而防火墙、病毒扫描器和其他保护手段是造成兼容性问题和系统崩溃的最常见原因。此外，病毒扫描器比计算机上的其他任何东西都要花费更多的时间，这种情况并不少见。作为操作系统一部分的安全软件通常比第三方安全软件更可靠。

9.  后台服务。许多在后台运行的服务对用户来说是不必要的，是对资源的浪费。考虑只在用户激活时运行服务。

10. 过多的特性。由于市场原因，软件通常会向每个新版本添加新特性。这可能会导致软件速度变慢或需要更多的资源，即使用户从不使用过这些新特性。

11. 认真对待用户反馈。用户的抱怨应该被视为关于bug、兼容性问题、可用性问题和所需新特性的有价值的信息来源。系统地处理用户反馈，确保信息得到合理利用。用户应该得到关于问题调查和解决方案计划的回复。应该很容易从网站上获得补丁。

# 5 选择最优算法

要优化CPU密集型软件，首先要找到最佳算法。算法的选择对于排序、搜索和数学计算等任务非常重要。在这种情况下，选择最好的算法比优化想到的第一个算法，你可以得到更多提升。在某些情况下，您可能需要测试几种不同的算法，以便找到在一组典型测试数据上最有效的算法。

话虽如此，我必须提醒不要过度。如果一个简单的算法可以足够快地完成这项工作，就不要使用高级和复杂的算法。例如，一些程序员甚至使用哈希表来存储很小的数据列表。对于非常大的数据库，哈希表可以显著地提高搜索时间，但是对于使用二分搜索甚至线性搜索的都可以很快完成列表，这就没有理由使用它。哈希表增加了程序的大小和数据文件的大小。如果瓶颈是文件访问或缓存访问，而不是CPU时间，这实际上会降低速度。复杂算法的另一个缺点是，它使程序开发成本更高，而且更容易出错。

对于不同目的的不同算法的讨论超出了本手册的范围。您必须查阅关于标准任务（如排序和搜索）的算法和数据结构的一般文献，或针对更复杂的数学任务的特定文献。

在开始编写代码之前，您可以考虑其他人是否已经在您之前完成了这项工作。针对许多标准任务的优化函数库有许多种来源。例如，[*Boost*](www.boost.org)包含许多常用的经过良好测试的库。“*Intel Math Kernek Library*”包含许多函数用于常见的数学计算包括线性代数和统计学，以及“Intel Performance Primitives”库包含许多含函数用于音频和视频处理，信号处理、数据压缩和密码学（[www.intel.com](www.intel.com)）。如果你正在使用*Intel*函数库，参见133页，确保在非*Intel*处理器上运作良好。

在开始编程之前选择最优算法通常说起来容易做起来难。许多程序员已经发现，只有在他们将整个软件项目放在一起并对其进行测试之后，才有更明智的方法来处理问题。通过测试和分析程序性能以及研究瓶颈获得的见解可以更好地理解问题的整个结构。这种新的见解可以导致程序的完全重新设计，例如，当你发现有更好的方法来组织数据时。

对一个已经投入使用的的程序进行彻底的重新设计当然是一项相当大的工作，但这可能是一项相当好的投资。重新设计不仅可以提高性能，可以得到更易于维护的、结构良好的程序。实际上，你花在重新设计程序上的时间可能比您花在解决原来设计糟糕的程序的问题上的时间要少。

# 6 开发过程
关于使用哪种软件开发过程和软件工程原则存在着相当多的争论。我不打算推荐任何具体的模型。相反，我将对开发过程如何影响最终产品的性能发表一些评论。

在规划阶段，最好对数据结构、数据流和算法进行全面的分析，以预测哪些资源是最关键的。然而，在早期规划阶段可能有许多未知的因素，因此很难对问题进行详细的概述。在后一种情况下，您可以将软件开发工作视为一个学习过程，其中主要的反馈来自于测试。在这里，您应该为多次迭代的重新设计做好准备。

一些软件开发模型具有严格的形式，它要求在软件的逻辑架构中有几个抽象层。您应该知道，这种形式主义有其固有的性能成本。将软件分割成过多的抽象层是降低性能的常见原因。

由于大多数开发方法本质上都是增量的或迭代的，所以一定要有一种策略来保存每个中间版本的备份。对于单人项目，制作每个版本的zip文件就足够了。对于团队项目，建议使用版本控制工具。


# 7 不同C++结构的效率
大多数程序员对于如何将一段程序代码转换成机器码以及微处理器如何处理这些代码，了解很少或者根本不了解。例如，许多程序员不知道双精度计算和单精度计算一样快。谁会知道模板类比多态类更有效呢?本章旨在解释不同*C++*语言元素的相对效率，以帮助程序员选择最有效的替代方案。本系列手册的其他卷进一步解释了理论背景。

## 7.1 不同类型的变量存储
变量和对象存在内存的存储位置，取决于它们在*C++*程序中是如何声明的。这会影响数据缓存的效率(参见第89页，TODO)。如果数据在内存中随机分布，则数据缓存的效率很低。因此，理解变量是如何存储的非常重要。对于简单的变量、数组和对象，存储原则是相同的。

### 栈存储（Storage on the stack）

函数中声明的变量和对象存储在栈中，但以下描述的几种情况除外。

栈是内存的一部分，以先入后出的方式组织。它用于存储函数返回地址（即函数是从哪里调用的）、函数参数、局部变量，以及保存在函数返回之前必须恢复的寄存器。每次调用函数时，它都会为所有这些目的在栈上分配所需的空间。当函数返回时释放该内存空间。下一次调用函数时，新函数的参数可以使用相同的空间。

因为重复使用相同范围的地址，栈是用来存储数据的效率最高的内存空间了。如果没有很大的数组，那么这一部分数据基本是缓存在一级缓存中的，而这里的访问速度是非常快的。

我们从中可以学到的教训是，所有变量和对象最好在使用它们的函数中声明。

通过在`{}`中声明变量，可以使变量的作用域更小。然而，大多数编译器在函数返回之前不会释放变量所使用的内存，即使在退出声明变量的`{}`时可以释放内存。如果变量存储在寄存器中（见下文），那么它可能在函数返回之前被释放。

### 全局或静态存储（Global or static storage）

在任何函数之外声明的变量称为全局变量。可以在任何函数中访问它们。全局变量存储在内存的静态部分中。静态内存还用于使用`static`关键字声明的变量、浮点常量、字符串常量、数组初始化器列表、`switch`语句跳转表和虚拟函数表。

静态数据区域通常分为三部分：一部分用于程序从不修改的常量，一部分用于程序可能会修改的初始化变量，另一部分用于程序可能会修改的未初始化变量。

静态数据的优点是可以在程序启动之前将其初始化为所需的值。缺点是内存空间在整个程序执行过程中都被占用，即使变量只在程序的一小部分中使用。这会降低数据缓存的效率。

如果可以避免，就不要定义全局变量。不同线程之间的通信可能需要全局变量，但这是惟一不可避免的情况。如果一个变量被多个不同的函数访问，或者你希望避免将变量做为函数的参数的额外开销，那么让它成为全局变量可能是有用的。但是，将需要访问相同变量的函数作为同一个类的成员函数并在类中保存共享的变量可能是一个更好的方案。当然你喜欢用你一种方案是编程分割的问题。

通常最好将查找表声明为`static`，例如

```
// Example 7.1
float SomeFunction (int x) {
    static float list[] = {1.1, 0.3, -2.0, 4.4, 2.5};
    return list[x];
}
```
在这里使用`static`的优点是在调用函数时不需要初始化这个数组。当程序加载到内存中时，这些值机会被放在那里。如果将上面的示例中的`static`这个词去掉，那么每次调用函数时都必须重新将所有这五个值放入数组中。这是通过将整个列表从静态内存复制到堆栈内存来完成的。在大多数情况下，从静态内存中复制常数数据到栈是在浪费时间。但这在特殊情况下可能是最好的：在循环中多次使用数据，而一级缓存已经被很多数组占用了，这时你可能会想把数据保存在栈上（, but it may be optimal in special cases where the data are used
many times in a loop where almost the entire level-1 cache is used in a number of arrays
that you want to keep together on the stack）。

字符串常量和浮点常量在优化后的代码中，被存储在静态内存中。例如：

```
// Example 7.2
a = b * 3.5;
c = d + 3.5;
```
在这里，常量`3.5`将会被存储在静态内存中。大多数编译器将识别出这两个常量是相同的，因此只需要存储一个常量。将整个程序中所有相同的常量连接在一起，以最小化常量使用的缓存空间。

整数常量通常包含在指令代码中。你可以假设整数常量不存在缓存问题。

### 寄存器存储（Register storage）

有限数量的变量可以存储在寄存器中而不是主存中。寄存器是CPU中用于临时存储的一小块内存。存储在寄存器中的变量可以被快速访问。所有优化编译器都会自动选择一个函数中最常用的变量存储在寄存器中。同一个寄存器可以用于多个变量，只要它们的使用（生存周期）不重叠。

寄存器的数量非常有限。在32位操作系统中，大约有6个整数寄存器可用于一般用途，而在64位系统中，有14个整数寄存器。

浮点变量使用不同类型的寄存器。32位操作系统中有8个浮点寄存器，64位操作系统中有16个浮点寄存器。
一些编译器很难在32位模式下生成浮点寄存器变量，除非启用了SSE2指令集（或更高版本）。

### 易变变量（Volatile）
`volatile`关键字用于声明一个变量可变被其它线程改变。这阻止编译器依赖于变量始终具有代码中先前分配的值的假设而进行优化。例如:

```
// Example 7.3. Explain volatile
volatile int seconds; // incremented every second by another thread
void DelayFiveSeconds() {
    seconds = 0;
    while (seconds < 5) {
    // do nothing while seconds count to 5
    }
}
```
在本例中，`DelayFiveSeconds`函数将等待，直到另一个线程将秒数增加到5。如果`seconds`没有声明为`volatile`，那么具有优化功能的编译器将假设秒在`while`循环中保持为零，因为循环中没有任何东西可以更改该值。循环`while(0 < 5){}`，将是一个无限循环。

要注意到`volatile`并不意味着原子性（`atomic`）。它不阻止两个线程同时改变变量。如果上面示例中的代码试图在其他线程增加`seconds`的同时将`seconds`置为零，那么它可能会失败。更安全的实现时只读取`seconds`的值，并等待该值更改五次。

### 线程本地存储（Thread-local storage）
大多数编译器可以使用关键字`__thread`或`__declspec(thread)`来实现静态变量和全局变量的线程本地存储。这样的变量对于每个线程都有一个实例。线程本地存储是低效的，因为它是通过存储在线程环境块中的指针进行访问的。如果可能的话，应该避免线程本地存储，并将其替换为栈上的存储（参见上文）。存储在栈中的变量总是属于创建它们的线程。

### Far

具有分段内存的系统，如*DOS*和16位*Windows*，允许使用关键字`far`（数组也可以用`huge`声明）将变量存储在其它数据段中。`far`存储、`far`指针和`far`过程是低效的。如果一个程序对于一个段（内存）有太多的数据，那么建议使用允许更大段的不同操作系统(32位或64位系统)。

### 动态内存分配

动态内存分配由`new`和`delete`操作符或`malloc`和`free`函数完成。这些操作符和函数消耗大量时间。内存中称为堆的一部分保留给动态分配。当以随机顺序分配和释放不同大小的对象时，堆很容易变得碎片化。堆管理器可以花费大量时间清理不再使用的空间并搜索空闲空间。这称为垃圾收集。按顺序分配的对象不一定按顺序存储在其中。当堆变的碎片化时，它们可能分散在不同的地方。这使得数据缓存效率低下。

动态内存分配还会使代码更复杂，更容易出错。程序必须保留指向所有已分配对象的指针，并跟踪它们何时不再使用。重要的是，在程序流的所有可能的情况下，也要释放所有分配的对象。不这样做是一个常见的导致错误的原因，称为内存泄漏。更糟糕的一种错误是在释放对象之后访问该对象。程序逻辑可能需要额外的开销来防止此类错误。

有关使用动态内存分配的优点和缺点的进一步讨论，请参见第92页（TODO）。

一些编程语言，如Java，对所有对象使用动态内存分配。这当然是低效的。

### 类中声明的变量

类中声明的变量按照它们在类声明中出现的顺序存储。存储类型由在哪里声明类的对象的决定。类、结构或联合的对象可以使用上面提到的任何存储方法。除了在最简单的情况下，对象不能存储在寄存器中，但是它的数据成员可以复制到寄存器中。

带有`static`修饰符的类成员变量将存储在静态内存中，并且只有一个实例。同一类的非静态成员将存储在该类的每个实例中。

将变量存储在类或结构中是一种很好的方法，可以确保在程序的相同部分中使用的变量也存储在彼此附近。使用类的优点和缺点见第52页(TODO)。

## 7.2 整数变量和运算符

### 整数大小

整数可以是不同的大小，可以有符号也可以无符号。下表总结了可用的不同整数类型。
<center>

|                                                   delaration                                                   | size, bits |  minimum value  |   maximum value   | in `stdint.h` |
| :------------------------------------------------------------------------------------------------------------: | :--------: | :-------------: | :---------------: | :-----------: |
|                                                    `char `                                                     |     8      |      -128       |        127        |   `int8_t`    |
|                                  `shortint` <br>in 16-bit system: `int` </br>                                  |     16     |     -32768      |       32767       |   `int16_t`   |
|                                `int`    <br>in 16-bit system: `long int` </br>                                 |     32     | -2<sup>31</sup> | 2<sup>31</sup>-1  |   `int32_t`   |
|               `long long`  or `int64_t`<br>MS compiler:`__int64`</br>  64-bit Linux: `long int`                |     64     | -2<sup>63</sup> | 2<sup>63</sup> -1 |   `int64_t`   |
|                                                `unsigned char`                                                 |     8      |        0        |        255        |   `uint8_t`   |
|                       `unsigned short int`    <br>in 16-bit system: `unsigned int` </br>                       |     16     |        0        |       65535       |  `uint16_t`   |
|                          `unsigned int`   <br>in 16-bit system: `unsigned long` </br>                          |     32     |        0        | 2<sup>32</sup> -1 |  `uint32_t`   |
| `unsigned long long` or `uint64_t` <br>MS compiler: `unsigned __int64`</br>  64-bit Linux: `unsigned long int` |     64     |        0        | 2<sup>64</sup> -1 |  `uint64_t`   |

**Table 7.1 Sizes of different integer types**

</center>

不幸的是，对于不同的平台，声明特定大小的整数的方式是不同的，如上表所示。如果标准头文件`stdin .h`或`inttypes.h`可用，则建议使用，以可移植的方式定义特定大小的整数类型。

无论大小如何，整数运算在大多数情况下都是很快的。但是，使用大于最大可用寄存器大小的整数大小是低效的。换句话说，在16位系统中使用32位整数或在32位系统中使用64位整数效率很低，特别是在代码涉及乘法或除法的情况下。

如你定义一个`int`类型，而不指定该类型的大小，编译器将始终选择最有效的整数大小。较小大小的整数（`char`，`short int`)的效率稍微低一些。在许多情况下，编译器在进行计算时将这些类型转换为默认大小的整数，然后只使用结果中较低的8或16位。您可以假设类型转换需要0或1个时钟周期。在64位系统中，只要不进行除法，32位整数和64位整数的效率之间只有极小的差别。

建议在大小无关且没有溢出风险的情况下使用默认整数大小，例如简单变量、循环计数器等。在大型数组中，为了更好地使用数据缓存，最好使用对于特定用途来说足够大的最小整数大小。大小不同于8、16、32和64位的位域（`Bit-fields`）效率较低。在64位系统中，如果应用程序可以使用额外的位，那么可以使用64位整数。

无符号整数类型`size_t`在32位系统中是32位，在64位系统中是64位。当您希望确保永远不会发生溢出时（即使是对于大于2 GB的数组），它可以被用于数组大小和数组索引。

在考虑特定整数大小是否足够大以满足特定用途时，必须考虑中间计算是否会导致溢出。例如，在表达式$a = (b*c)/d$中，即使$a$、$b$、$c$和$d$都低于最大值，也可能发生（$b*c$）溢出。这里没有对整数溢出的自动检查。

### 有符号整数 VS 无符号整数

在大多数情况下，使用有符号整数和无符号整数在速度上没有区别。但在一些情况下会有一些区别：

1. 除以常数：当你用一个整数除一个常数时，无符号要快于有符号（参见第141页:TODO）。这也适用于模运算符`%`。
2. 对于大多数指令集，有符号整数转换为浮点数要比无符号整数快(参见第145页)。
3. 有符号变量和无符号变量的溢出行为不同。无符号变量的溢出会产生较低的正数结果。带符号变量的溢出没有被正式定义。正常的行为下，正溢出将会变为负值，但是编译器可以基于不会发生溢出的假设，优化掉依赖于溢出的分支。

有符号整数和无符号整数之间的转换是无代价的。这仅仅是对相同的位进行不同的解释。负整数在转换为无符号时将被解释为一个非常大的正数。

```
// Example 7.4. Signed and unsigned integers
int a, b;
double c;
b = (unsigned int)a / 10; // Convert to unsigned for fast division
c = a * 2.5; // Use signed when converting to double
```
在示例7.4中，我们将`a`转换为无符号，以使除法更快。当然，这只在确定`a`永远不会为负的情况下有效。最后一行是将`a`隐式转换为`double`然后乘以常数`2.5`，也是`double`类型的。在这里我们希望`a`是有符号的。

确保不要在比较中混合有符号整数和无符号整数，例如`<`。比较有符号整数和无符号整数的结果是模糊的，可能会产生不希望的结果。

### 整数操作符

整数运算通常非常快。在大多数微处理器上，简单的整数操作（如加减、比较、位操作和移位操作）只需一个时钟周期。

乘法和除法需要更长的时间。在奔腾4处理器上，整数乘法需要11个时钟周期，在大多数其他微处理器，需要3-4个时钟周期。整数除法需要40 - 80个时钟周期，具体取决于微处理器。整数除法在AMD处理器上整数大小（size）越小速度越快，但在英特尔处理器上不会这样。关于指令延迟的详细信息列在手册4:“Instruction tables”中。关于如何加速乘法和除法的技巧，分别在第139页和第141页给出（TODO）。

### 自增和自减运算符

增量（前缀）运算符`++i`和增量（后缀）运算符`i++`和加法一样快。当仅用于递增整数变量时，使用递增前或递增后都没有区别。效果完全相同。例如,`for (i=0; i<n; i++)`和`for (i=0; i<n; ++i)`是一样的。：但是当使用表达式的结果时，效率可能会有所不同。例如，`x = array[i++]`比`x = array[++i]`更有效率，因为在后一种情况下，数组元素的地址的计算必须等待`i`的新值，这将使`x`的可用性延迟大约两个时钟周期。显然，如果将增量（前缀）更改为增量（后缀），则必须调整`i`的初始值。

还有一些情况下，增量（前缀）比增量（后缀）更有效。例如，在`a = ++b`的情况下；编译器会在这条语句之后识别出`a`和`b`的值是相同的，这样它就可以对两者使用相同的寄存器，而表达式`a = b++`，将使`a`和`b`的值不同，这样它们就不能使用相同的寄存器。

这里所说的关于递增运算符的所有内容也适用于整数变量上的递减运算符。

## 7.3 浮点变量和操作符
*x86*家族中的现代微处理器有两种不同类型的浮点寄存器，相应地也有两种不同类型的浮点指令。每种类型都有各有优缺点。

进行浮点运算的原始方法涉及到将8个浮点寄存器组成一个寄存器栈（register stack）。这些寄存器具有长双精度（80位）。使用寄存器栈的优点是:
1. 所有的计算都是长双精度的。
2. 不同精度之间的转换不需要额外的时间。
3. 对于数学函数，如对数函数和三角函数，有一些指令可用。
4. 码很紧凑，在代码缓存中占用的空间很小。

寄存器堆栈也有缺点：
1. 由于寄存器堆栈的组织方式，编译器很难生成寄存器变量。
2. 浮点数比较比较慢，除非使用奔腾-II或者更新的指令集。
3. 整数和浮点数之间的转换效率很低。
4. 当使用长双精度时，除法、平方根和数学函数需要更多的时间。

还有一种新的浮点运算方法涉及8个或16个向量寄存器（*XMM*或*YMM*)，可用于多种用途。浮点运算以单精度或双精度进行，中间结果的计算精度始终与操作数相同。使用向量寄存器的优点是:
1. 浮点寄存器变量很容易实现
2. 矢量运算可用于对*XMM*寄存器中两个双精度或四个单精度变量的矢量进行并行计算(参见第107页,TODO)。如果*AVX*指令集是可用的，那么在YMM寄存器中每个向量可以容纳4个双精度或8个单精度变量。

缺点是：
1. 不支持长双精度
2. 在运算数具有混合精度的表达式的计算需要精确的转换指令，这可能非常耗时（参见第143页，TODO）。
3. 数学函数必须使用函数库，但这通常比硬件函数更快。

浮点堆栈寄存器在所有具有浮点功能的系统中都可用（64位*Windows*的设备驱动程序除外）。*XMM*向量寄存器可以在64位系统中使用，也可以在启用*SSE2*或更高的指令集时在32位系统中使用(单精度只需要*SSE*)。如果处理器和操作系统支持*AVX*指令集，则可以使用*YMM*寄存器。有关如何测试这些指令集的可用性，请参见第125页(TODO)。

当*XMM*寄存器可用时，大多数编译器都会使用它进行浮点计算，例如在64位系统中，或者启用*SSE2*指令集时。很少有编译器能够混合这两种类型的浮点运算，并为每种计算选择最优的类型。

在大多数情况下，双精度计算不会比单精度计算花费更多的时间。当使用浮点寄存器时，单精度和双精度的速度没有差别。长双精度只需要稍多一点的时间。单精度的除法、平方根和数学函数的计算速度都快于双精度。当使用*XMM*寄存器时，加、减、乘等操作的速度，无论精度如何，在大多数处理器上仍是相同的（没有使用向量操作）。

如果对应用程序有好处，可以使用双倍精度，而不必太担心成本。如果您有大数组，并且希望将尽可能多的数据放入数据缓存，则可以使用单精度。如果可以利用向量操作，单精度是最好的，如107页所述（TODO）。

根据微处理器的不同，浮点加法需要3 - 6个时钟周期。乘法需要4 - 8个时钟周期。除法需要14 - 45个时钟周期。当使用浮点堆栈寄存器时，浮点比较是低效的。在使用浮点堆栈寄存器时，浮点或双精度浮点到整数的转换需要很长时间。

当使用*XMM*寄存器时，不要混合使用单精度和双精度。见143页（TODO）。

如果可能的话，避免整数和浮点变量之间的转换。见144页（TODO）。

在*XMM*寄存器中长生浮点浮点数向下溢出的应用程序，可以从`flush-to- zero`模式而不是在向下溢出的情况下生成非规格化数（*subnormal number*）中获益:

```
// Example 7.5. Set flush-to-zero mode (SSE):
#include <xmmintrin.h>
_MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);
```
强烈建议设置为`flush-to-zero`模式，除非有特殊原因需要使用非规格话数。此外，如果*SSE2*可用，你可以设置`denormars-are-zero`模式:

```
// Example 7.6. Set flush-to-zero and denormals-are-zero mode (SSE2):
#include <xmmintrin.h>
_mm_setcsr(_mm_getcsr() | 0x8040);
```
有关数学函数的更多信息，请参阅第149和122页(TODO)。

## 7.4 枚举
`enum`只是一个隐藏的整数。枚举的效率和整数一样。注意，枚举数（值名）将与具有相同名称的任何变量或函数冲突。因此，头文件中的枚举应该具有长且唯一的枚举数名称，或者将其放在命名空间中。

## 7.5 布尔值

### 布尔操作数的顺序

布尔运算符`&&`和`||`的操作数将会按照下面的顺序就行计算。如果`&&`的第一个操作数为`false`，那么就不会计算第二个操作数的值，因为表达式的结果无论第二个操作数的值是`true`还`false`，都为`false`。类似的，如果`||`的第一个操作数为`true`，那么也不会计算第二个操作数的值，因为无论如何结果都为`true`。

将通常为`true`的操作数放在`&&`表达式的最后，或者作为`||`表达式的第一个操作数中，这可能是有好处的。例如，假设`a`在$50\%$的情况下为真b在$10\%$的情况下为真。当`a`为真时，表达式`a && b`需要对`b`求值，即
$50\%$的情况。等价表达式`b && a`只需要在`b`为`true`时对`a`求值，只有10%的情况。如果`a`和`b`的计算时间相同，并且分支预测机制预测的可能性相同，这样的计算速度会更快。有关分支预测的解释，请参见第43页（TODO）。

如果一个操作数比另一个更可预测，那么将最可预测的操作数放在前面。

如果一个操作数的计算速度快于另一个操作数，则将计算速度最快的操作数放在首位。

但是，在交换布尔操作数的顺序时必须小心。如果操作数的求值有副作用，或者如果第一个操作数决定第二个操作数是否有效，则不能交换操作数。例如：

```
// Example 7.7
unsigned int i; 
const int ARRAYSIZE = 100; 
float list[ARRAYSIZE];
if (i < ARRAYSIZE && list[i] > 1.0) { ...
```
在这里，您不能交换操作数的顺序，因为当`i`不小于`ARRAYSIZE`时，表达式`list[i]`是无效的。另一个例子:

```
// Example 7.8
if (handle != INVALID_HANDLE_VALUE && WriteFile(handle, ...)) { ...
```

### 布尔变量被过度检查（overdetermined）

布尔变量存储在8位整数中，`0`代表`false`, `1`代表`true`。

布尔变量是过度检查的，因为所有以布尔变量作为输入的运算符都要检查输入是否有除`0`或`1`之外的值，但是以布尔值作为输出的运算符只能产生0或1之外的值。这使得使用布尔变量作为输入的操作效率低于可能的效率。比如说：

```
// Example 7.9a
bool a, b, c, d;
c = a && b;
d = a || b;
```

编译器通常是以以下方式实现：

```
bool a, b, c, d;
if (a != 0) {
    if (b != 0) {
        c = 1;
    }
    else {
        goto CFALSE;
    }
}
else {
CFALSE:
    c = 0;
}
if (a == 0) {
    if (b == 0) {
        d = 0;
    }
    else {
    goto DTRUE;
    }
}
else {
DTRUE:
    d = 1;
}
```

这当然远远不是最优的。为了防止错误的预测，这些分支可能耗费很长的时间（详见第43页，TODO）。如果知道操作数除了`0`就是`1`，布尔运算可以变得有效率的多。编译器之所以不这样假设，是因为如果变量是没有被初始化的或者是来自其它未知来源的。如果`a`和`b`被初始化为有效的值，或者他们来自输出 Boolean 值的操作符，那么上述代码是可以被优化的。优化后的代码类似下面这样：

```
// Example 7.9b
char a = 0, b = 0, c, d;
c = a & b;
d = a | b;
```
在这里我使用`char`（或`int`）来代替`bool`,是为了使用位操作符（`&`和`|`）代替布尔操作符（`&&`和`||`）。位操作符是单条指令，只需一个时钟周期。即使`a`和`b`不是`0`或`1`，`OR`操作符（`|`)也可以正常工作。如果操作数有不是`0`或`1`的值，`AND`（`&`）操作符和`EXCLUSIVE OR`操作符（`^`）可能会产生不一致的结果。

请注意到这里有几个陷阱（pitfalls）。你不能使用`~`代替`NOT`。相反，如果已知变量的值为`0`或`1`，你可以对变量`XOR`上`1`，来对变量进行取反操作（*Boolean NOT*）。

```
// Example 7.10a
bool a, b;
b = !a;
```
可以被优化为：

```
// Example 7.10b
char a = 0, b;
b = a ^ 1;
```
如果打`a`为*false*时，表达式不应该被计算的话，你不能使用`a&b`代替`a&&b`。类似的，如果当`a`为*true*时，表达式不应该被计算的话，不能用`a|b`代替`a||b`。

使用位操作符的技巧在操作数时变量而不是比较表达式等其它情况时，更有优势。例如：

```
// Example 7.11
bool a; float x, y, z;
a = x > y && z != 0;
```
上述形式在大多数情况下通常是最优的。不要把`&&`改成`&`，除非你希望`&&`表达式产生很多错误的分支预测。

### 布尔向量操作：

一个整数可以被当作布尔向量使用。例如，如果`a`和`b`是32位整数，那么表达式`y=a&b`，将会在一个时钟周期中进行32个与操作。操作符`&`，`|` ，`^` ，`~`对于布尔向量操作都非常常用。

## 7.6 指针和引用

### 指针 VS 引用

指针和引用的效率是一样的，因为它们实际上做的事情是相同的。例如：

```
// Example 7.12
void FuncA (int * p) {
    *p = *p + 2;
}
void FuncB (int & r) {
    r = r + 2;
}
```
这两个函数做的是相同的事情，如果您查看编译器生成的代码，您会注意到这两个函数的代码完全相同，区别仅仅在于编程风格。使用指针的优点是:
1. 当你查看上面的函数体时，可以清楚地看到`p`是一个指针，但是不清楚`r`是一个引用还是一个简单的变量。使用指针使读者更清楚地了解正在发生的事情。
2. 可以用指针做引用不可能做的事情。你可以改变指针指向什么，你可以用指针做算术运算。

使用引用的优点是：
1. 使用引用时语法更简单。
2. 引用比指针更安全，因为在大多数情况下，它们肯定指向一个有效的地址。如果指针没有初始化，或者指针算术计算超出了有效地址的范围，亦或是指针被转换为错误的类型，指针可能无效并导致致命错误。
3. 对于复制构造函数和重载操作符来说，引用更加常用。
4. 被声明为常量引用的函数参数接受表达式作为参数，而指针和非常量引用则需要一个变量。

### 效率

通过指针或引用访问变量或对象可能与直接访问它一样快。拥有这种效率的原因在于微处理器的构造方式。函数中声明的所有非静态变量和对象都存储在堆栈中，并且实际上是相对于栈指针寻址的。同样，我们知道在*C++*中。类中声明的所有非静态变量和对象都可以通过已知的隐式指针`“this”`进行访问。因此，我们可以得出这样的结论：结构良好的*C++*程序中的大多数变量实际上都是通过指针这种方式访问的，这就是效率相同的原因。然而，使用指针和引用也有缺点。最重要的是，它需要一个额外的寄存器来保存指针或引用的值。寄存器是一种稀缺资源，尤其是在32位模式下。如果没有足够的寄存器，那么指针每次使用时都必须从内存中加载，这会使程序变慢。另一个缺点是指针的值需要几个时钟周期才能访问所指向的变量。

### 指针运算
指针实际上是一个保存内存地址的整数。因此，指针算术运算和整数算术运算一样快。当一个整数被添加到一个指针时，它的值乘以所指向的对象的大小。例如:

```
// Example 7.13
struct abc {int a; int b; int c;};
abc * p; int i;
p = p + i;
```
在这里，`p`所增加的值不是`i`而是`i*12`，因为`abc`的大小是12个字节。`p`加上`i`的时间等于做乘法和加法的时间的和。如果`abc`的大小是2的幂，那么乘法可以被移位运算代替，移位运算要快得多。在上面的示例中，通过向结构体中添加一个整数，`abc`的大小可以增加到16字节。

递增或递减指针不需要乘法，只需要加法。比较两个指针只需要一个整数比较，这是很快的。计算两个指针之间的差值需要一个除法，这是很慢的，除非所指向的对象类型的大小是2的幂（关于除法，请参阅第141页，TODO）。

在计算指针的值之后，访问所指向的对象大约需要两个时钟周期。因此，建议在使用指针之前计算该指针的值。例如，`x = *(p++)`比`x = *(++p)`更高效，因为在后一种情况下，`x`的读取必须在指针`p`被递增后等待几个时钟周期，而在前一种情况下，`x`可以在`p`在递增之前被读取。有关递增和递减运算符的更多讨论，请参见7.2节关于递增和递减运算的讨论。

## 7.7 函数指针
如果可以预测目标地址，那么通过函数指针调用函数通常要比直接调用函数多花几个时钟周期。如果函数指针的值与上次执行语句时相同，则可以预测目标地址。如果函数指针的值发生了变化，那么目标地址很可能会被错误地预测，从而导致长时间的延迟。有关分支预测，请参见第43页（TODO）。如果函数指针的变化遵循一个简单的规则，奔腾M处理器可能能够预测目标地址，而奔腾4和AMD处理器一定会做出错误的预测，只要函数指针发生了变化。

## 7.8 成员指针（Member pointers）
在简单的情况下，数据成员指针只是存储数据成员相对于对象开头的偏移量，而成员函数指针只是成员函数的地址。但是在一些特殊的情况下，比如需要更复杂实现的多重继承。一定要避免这些复杂的情况。

如果编译器没有关于成员指针所引用的类的完整信息，那么它必须使用最复杂的成员指针实现。例如:

```
// Example 7.14
class c1;
int c1::*MemberPointer;
```
在这里，声明`MemberPointer`时，编译器除了类`c1`的名称之外，没有其他关于类`c1`的信息。因此，它必须假设最坏的情况，并对成员指针进行复杂的实现。可以通过在声明`MemberPointer`之前完整地声明`c1`来避免这种情况。避免*多重继承*、*虚函数*和其他会降低成员指针效率的复杂情况。

大多数*C++*编译器都有不同的选项来控制成员指针的实现方式。如果可能的话，使用尽可能简单的实现选项，并确保对使用相同成员指针的所有模块使用相同的编译器选项。

## 7.9 智能指针
智能指针是一个行为像指针的对象。它有一个特殊的特性，当指针被删除时，它所指向的对象被删除。智能指针仅用于使用`new`存储在动态分配内存中的对象。使用智能指针的目的是确保对象被正确删除，以及在对象不再使用时释放内存。智能指针可以被认为是只包含单个元素的容器。

智能指针最常见的实现是`auto_ptr`和`shared_ptr`。`auto_ptr`的特性是，始终只有一个`auto_ptr`拥有所分配的对象，并且通过赋值将所有权从一个`auto_ptr`转移到另一个`auto_ptr`。`shared_ptr`则允许多个指针指向同一个对象。

通过智能指针访问对象没有额外的成本。无论`p`是简单指针还是智能指针，通过`*p`或`p->member`访问对象的速度都是一样快的。但是，每当创建、删除、复制或从一个函数转移到另一个函数时，都会产生额外的成本。`shared_ptr`的这些成本要高于`auto_ptr`。

当程序的逻辑结构要求一个对象必须由一个函数动态创建，然后由另一个函数删除，并且这两个函数互不相关（不是同一个类的成员）时，智能指针非常有用。如果相同的函数或类负责创建和删除对象，则不需要使用智能指针。

如果一个程序为每个智能指针使用许多动态分配的小对象，那么需要考虑一下这个解决方案的成本是否太高。将所有对象合用到一个容器中可能更有效，最好是使用连续内存。参见第95页（TODO）关于容器类的讨论。

## 7.10 数组
数组是通过在内存中连续存储元素来实现的。没有存储关于数组大小的信息。这使得在`C`和`C++`中使用数组比在其他编程语言中更快，但也更不安全。这个安全问题可以通过定义一个容器类来解决，该类的行为类似于一个带有边界检查的数组，如下例所示:

```
// Example 7.15a. Array with bounds checking
template <typename T, unsigned int N> class SafeArray {
    protected:
        T a[N]; // Array with N elements of type T39
    public:
        SafeArray() { // Constructor
            memset(a, 0, sizeof(a)); // Initialize to zero
        }
        int Size() { // Return the size of the array
            return N;
        }
        T & operator[] (unsigned int i) { // Safe [] array index operator
            if (i >= N) {
                // Index out of range. The next line provokes an error.
               // You may insert any other error reporting here:
                return *(T*)0; // Return a null reference to provoke error
            }
            // No error
            return a[i]; // Return reference to a[i]
        }
};
```
[ www.agner.org/optimize/cppexamples.zip](www.agner.org/optimize/cppexamples.zip)中给出更多关于容器类的例子。

使用上述模板类的数组是通过将类型和大小指定为模板参数来声明的，如下面的示例7.15b所示。可以使用方括号索引访问它，就像普通数组一样。构造函数将所有元素设置为零。如果你不希望这个初始化，或者类型T是一个具有默认构造函数的类，它会执行必要的初始化，那么可以删除`memset`这一行。编译器可能会报告`memset`已被弃用。这是因为如果参数`size`错误，它会导致错误，但它仍然是将数组设置为0的最快方法。如果索引超出范围，`[]`操作符将检测到错误（参见第137页的边界检查，TODO）。在这里，通过返回空引用这一非常非常规的方式引发错误消息。如果数组元素被访问，这将在受保护的操作系统中引发错误消息，并且这个错误很容易通过调试器跟踪。您可以用任何其他形式的错误报告来替换这一行。例如，在*Windows*中，你可以这么写：`FatalAppExitA(0，"Array index out of range");`，或者更好的是，创建自己的错误消息函数。

下面的例子演示了如何使用`SafeArray`：

```
// Example 7.15b
SafeArray <float, 100> list; // Make array of 100 floats
for (int i = 0; i < list.Size(); i++) { // Loop through array
     cout << list[i] << endl; // Output array element
}
```
由列表初始化的数组最好是静态的，如7.1节，*全局或静态存储*中所述。数组可以使用`memset`初始化为0：

```
// Example 7.16
float list[100];
memset(list, 0, sizeof(list));
```
应该按顺序访问多维数组，保证最后一个索引变化最快（“A multidimensional array should be organized so that the last index changes fastest”）：

```
// Example 7.17
const int rows = 20, columns = 50;
float matrix[rows][columns];
int i, j; float x;
for (i = 0; i < rows; i++)
for (j = 0; j < columns; j++)
matrix[i][j] += x;
```
这确保元素是按顺序访问的。这两个循环的相反顺序将使访问是非顺序的，这将降低数据缓存的效率。如果为了使地址计算更高效，不按顺序索引，那么除了第一个维度外，所有维度的大小最好是2的幂：

```
// Example 7.18
int FuncRow(int); int FuncCol(int);
const int rows = 20, columns = 32;
float matrix[rows][columns];
int i; float x;
for (i = 0; i < 100; i++)
    matrix[FuncRow(i)][FuncCol(i)] += x;
```
在这里，代码必须计算`(FuncRow(i)*columns + FuncCol(i)) * sizeof(float)`才能找到矩阵元素的地址。在这种情况下，当大小是2的幂时，乘上列数的速度更快。在前面的示例中，这不是问题，因为编译器优化可以看到这些行是连续访问的，并且可以通过将行长度添加到前一行的地址来计算每行的地址。

同样的建议也适用于结构或类对象的数组。如果以非顺序访问元素，则对象的大小(以字节为单位)最好为2的幂。

将列数设置为2的幂的建议并不总是适用于大于一级数据缓存且以非顺序访问的数组，因为这可能会导致缓存竞争。关于这个问题的讨论请参阅第89页（TODO）。

## 7.11 类型转换
*C++*语法有几种不同的类型转换方法：

```
// Example 7.19
int i; float f;
f = i; // Implicit type conversion
f = (float)i; // C-style type casting
f = float(i); // Constructor-style type casting
f = static_cast<float>(i); // C++ casting operator
```
这些不同的方法有完全相同的效果。使用哪种方法取决于编程风格。下面讨论不同类型转换的时间消耗。

### <u>signed/unsigned 转换</u>

```
// Example 7.20
int i;
if ((unsigned int)i < 10) { ...
```
有符号整数和无符号整数之间的转换只是使编译器换一种解释整数的不同位的方法。没有检查溢出，代码没有消耗额外的时间。这些转换可以随意使用，而不需要担心任何性能成本。

### <u>整型大小的转换</u>

```
// Example 7.21
int i; short int s;
i = s;
```
如果整数有符号，则通过扩展符号位将其转换为更大的大小；如果没有符号，则通过扩展0将其转换为更大的大小。如果代码是算术表达式，这通常需要一个时钟周期。如果是从内存中的变量中读取值，则大小转换通常不需要额外的时间，如示例7.22所示：

```
// Example 7.22
short int a[100]; int i, sum = 0;
for (i=0; i<100; i++) sum += a[i];
```
将整数转换成较小的大小只需忽略较高的位即可。没有溢出检查。例如：

```
// Example 7.23
int i; short int s;
s = (short int)i;
```
这种转换不需要额外的时间。它只存储32位整数中较低的16位。

### <u>浮点精度转换</u>
当使用浮点寄存器栈时，浮点、双精度和长双精度之间的转换不需要额外的时间。使用*XMM*寄存器时，需要2到15个时钟周期（取决于处理器）。有关寄存器栈与*XMM*寄存器的区别，请参见*7.3 浮点变量和操作符*。例如：

```
// Example 7.24
float a; double b;
a += b;
```
在本例中，如果使用*XMM*寄存器，那么转换的成本很高。为了避免这种情况，`a`和`b`应该是同一类型的。进一步讨论请参阅第143页(TODO)。

### <u>整型转换为浮点型</u>

将有符号整数转换为浮点数或双精度浮点数需要4 - 16个时钟周期，这取决于处理器和使用的寄存器类型。无符号整数的转换需要更长的时间。如果没有溢出的风险，首先将无符号整数转换为有符号整数会更快：

```
// Example 7.25
unsigned int u; double d;
d = (double)(signed int)u; // Faster, but risk of overflow
```

整型到浮点型的转换有时可以通过将整数替换为浮点型变量来避免。例如:

```
// Example 7.26a
float a[100]; int i;
for (i = 0; i < 100; i++) a[i] = 2 * i;
```
在本例中，可以通过添加一个浮点变量来避免`i`转换为`float`:

```
// Example 7.26b
float a[100]; int i; float i2;
for (i = 0, i2 = 0; i < 100; i++, i2 += 2.0f)
    a[i] = i2;
```

### <u>浮点型转换为整型</u>

如果不启用*SSE2*或者更新的指令集，浮点数到整数的转换将花费很长时间。通常，转换需要50 - 100个时钟周期。原因是*C/ C++*标准指定了截断，因此浮点四舍五入的模式必须更改为截断并再次返回。如果在代码的关键部分存在浮点数到整数的转换，那么对其采取一些措施是很重要的。可能的解决方案是：
1. 使用不同类型的变量避免转换。
2. 通过将中间结果存储为浮点数，将转换移出最内层循环。
3. 使用64位模式或启用*SSE2*指令集（需要一个支持该模式的微处理器）。
4. 使用四舍五入代替截断，并用汇编语言制作一个舍入函数。有关舍入的详细信息，请参见第144页（TODO）。

### <u>指针类型转换</u>

指针可以转换为另一种类型的指针。同样，可以将指针转换为整数，也可以将整数转换为指针。重要的是整数有足够的位来保存指针。

这些转换不会产生任何额外的代码。这仅仅是用不同的方式解释相同的位或者绕过语法检查的问题。

当然，这些转换是不安全的。程序员有责任确保结果是有效的。

### <u>重新解释对象</u>

通过类型转换它的地址，编译器可以将一个变量或对象当作另一个不同的类型来处理:

```
// Example 7.27
float x;
*(int*)&x |= 0x80000000; // Set sign bit of x
```
这里的语法可能看起来有点奇怪。将`x`的地址类型转换为指向整数的指针，然后对该指针取值，以便将`x`作为整数访问。编译器不会生成任何额外的代码来实际创建指针。指针被简单地优化掉了，结果是`x`被当作一个整数。但是,运算符强制编译器将`x`存储在内存中，而不是寄存器中。上面的示例使用`|`操作符设置`x`的符号位，只能应用于整数。这样操作比`x = -abs(x)`更快。

在类型转换指针时，有许多危险的地方需要注意：
1. 这个技巧违反了标准C的严格的别名规则，规定不同类型的两个指针不能指向相同的对象（`char`指针除外）。编译器优化可以将浮点数和整数表示形式存储在两个不同的寄存器中。你需要检查编译器是否按照您希望的方式运行。使用union会更安全，如146页（TODO）例14.23所示。
2. 如果将对象视为比实际更大的对象，这个技巧就会失效。如果`int`比`float`使用更多的位，上面的代码将会失败。（两者在x86系统中都使用32个位）。
3. 如果你只访问变量的一部分，例如64位双精度浮点数中的32位，那么代码将无法移植到使用大端存储的平台上。
4. 如果你以部分访问的方式访问变量，例如，如果您一次操作64位`double`类型的32位，那么由于CPU中的存储转发延迟，代码的执行速度可能会低于预期（参见手册3:“The microarchitecture of Intel, AMD and VIA CPUs”）。

### <u>const_cast</u>

`const_cast`操作符用于解除`const`对指针的限制。它有一些语法检查，因此比C风格的类型转换更安全，er无需添加任何额外的代码。例如：

```
// Example 7.28
class c1 {
    const int x; // constant data
public:
    c1() : x(0) {}; // constructor initializes x to 0
    void xplus2() { // this function can modify x
        *const_cast<int*>(&x) += 2;} // add 2 to x
};
```
这里`const_cast`操作符的作用是消除`x`上的`const`限制，这是一种解除语法限制的方法，但它不会生成任何额外的代码，也不会花费任何额外的时间。这是确保一个函数可以修改`x`，而其他函数不能修改`x`的有用方法。

### <u>static_cast</u>

`static_cast`操作符的作用与C风格的类型转换相同。例如，它用于将`float`转换为`int`。

### <u>reinterpret_cast</u>
`reinterpret_cast`操作符用于指针转换。它的作用与C风格类型转换相同，只是多了一点语法检查。它不产生任何额外的代码。

### <u>dynamic_cast</u>

`dynamic_cast`操作符用于将指向一个类的指针转换为指向另一个类的指针。它在运行时检查转换是否有效。例如，当基类的指针转换为派生类的指针时，它检查原始指针是否实际指向派生类的对象。这种检查使得`dynamic_cast`比简单类型的转换更耗时，但也更安全。它可能会捕获那些无法检测到的编程错误。

### <u>转换类对象</u>

只有当程序员定义了构造函数、重载赋值运算符或重载类型转换运算符（指定如何进行转换）时，才有可能进行涉及类对象（而不是指向对象的指针）的转换。构造函数或重载操作符与成员函数的效率是一样的。

## 7.12 分支和switch语句
现代微处理器的高速运转是通过一个流水线（pipeline）来实现的，指令在执行之前，会在不同的几个阶段中被提取和解码。然而,流水线结构有一个大问题。当代码有分支时（例如`if-else`），微处理器事先不知道要给这两个分支中的哪个分支的数据送入流水线。如果将错误的分支送入管道，它通过读取、解码等方式所完成的工作，需要等到10 - 20个时钟周期以后才被检测到产生错误，在这段时间内投机性地执行指令是在浪费时间。结果是微处理器会将一个分支数据送入，只要稍后发现选择错了分支，那么就会浪费掉几个时钟周期。

微处理器设计者已经竭尽全力减少这个问题。其中最重要的方法是分支预测。现代微处理器使用先进的算法，根据该分支和附近其他分支的过去历史来预测分支的发展方向。对于不同类型的微处理器，用于分支预测的算法是不同的。这些算法在手册3“The microarchitecture of Intel, AMD and VIA CPUs”中有详细的描述。

在微处理器做出正确预测的情况下，分支指令通常需要0 - 2个时钟周期。根据处理器的不同，从分支错误预测中恢复所需的时间大约为12 - 25个时钟周期。这被称为分支错误预测的惩罚。

如果大多数时候分支是可预测的，那么它们消耗很少；但是如果预测错误，那么它们的消耗就大了。当然，总是沿着同一方向发展的分支是可预测的。一个分支在大多数情况下是单向的，很少是反向的，只有当它向另一个方向发展时，才会出现错误的预测。一个分支向一个方向走了很多次，然后又向另一个方向走了很多次，只有当它发生变化时才会被错误地预测。如果一个遵循简单周期模式的分支，在一个有很少或没有其它分支的循环中，那么也可以很好地进行预测。一个简单的周期模式可以是，例如，一条路走两遍，另一条路走三遍。同样的，两倍第一种方法，三倍另一种方法，等等。最坏的情况是一个分支随机地向一个方向或另一个方向移动，任意方向的概率都是50%。这样的分支有50%的几率会预测错误。

`for`循环或`while`循环也是一种分支。在每次迭代之后，它决定是重复还是退出循环。如果重复计数很小且始终相同，则通常可以很好地预测循环分支。根据处理器的不同，可以完美预测的最大循环数在9到64之间变化。嵌套循环只能在某些处理器上得到很好的预测。在许多处理器上，包含多个分支的循环并不能很好地被预测。

`switch`语句也是一种分支，它可以有两个以上的分支。如果`case`标签是遵循每个标签等于前一个标签加1的序列，那么`switch`语句是最高效的，因为它可以被实现为一个目标跳转表。如果switch语带有许多标签值，并且彼此相差很远，这将是低效的，因为编译器必须将其转换成一个分支树。

在较老的处理器上，会简单的认为带有顺序标签的`switch`语句的执行分支与上一次相同。因此，无论何时它走了不是上次走的分支，它肯定会被错误地预测。较新的处理器有时能够预测一个`switch`语句，如果它遵循一个简单的周期模式，或者它与前面的分支相关，并且不同目标的数量很少。

分支和`switch`语句的数量最好在程序的关键部分控制在较少的水平，特别是在分支的可预测性较差的情况下。那么展开循环可以消除分支，那这可能是有用的，这将在下一段中解释。

分支和函数调用的目标保存在称为分支目标缓冲区的特殊缓存中。如果一个程序有许多分支或函数调用，那么在分支目标缓冲区中就会产生竞争。这种竞争的结果是，即使分支有良好的可预测性，它们也可能被错误地预测。由于这个原因，甚至函数调用也可能被错误地预测。因此，在代码的关键部分具有许多分支和函数调用的程序可能会收到错误预测的影响。

在某些情况下，可以用表查找来替换难以预测的分支。例如：

```
// Example 7.29a
float a; bool b;
a = b ? 1.5f : 2.6f;
```

`?:`操作符在这里就是一个分支。如果它的可预测性很差，那么可以用一个表查找来代替它：

```
// Example 7.29b
float a; bool b = 0;
const float lookup[2] = {2.6f, 1.5f};
a = lookup[b];
```
如果将`bool`变量用作数组索引，那么需要确保它被初始化或来自可靠的源，这非常重要，这样它除了0或1之外就不会有其他值。见*7.5 布尔值-布尔变量被过度检查*。

在某些情况下，编译器可以根据指定的指令集，自动使用条件转移替换分支。

第137页和139页（TODO）的例子展示了减少分支数量的各种方法。

手册3:“The microarchitecture of Intel, AMD and VIA CPUs”提供了不同微处理器中分支预测的更多细节。

## 7.13 循环
循环的效率取决于微处理器对循环制分支的预测能力。有关分支预测的说明，请参阅前文和手册3:“The microarchitecture of Intel, AMD and VIA CPUs”。一个具有一个较小并且固定的重复计数，没有分支的循环，可以完美地被预测。如上所述，可以预测的最大循环数取决于处理器。只有在某些具有特殊循环预测器的处理器上，嵌套循环才能很好地进行预测。在其他处理器上，只能很好地预测最里面的循环。只有在循环退出时，才会错误地预测具有高重复计数的循环。例如，如果一个循环重复1000次，那么循环控制分支在1000次中只会出现一次错误预测，因此错误预测惩罚对总执行时间的影响可以忽略不计。

### <u>循环展开</u>

在某些情况下，展开循环可能很有益处。例如：

```
// Example 7.30a
int i;
for (i = 0; i < 20; i++) {
    if (i % 2 == 0) {
        FuncA(i);
    }
    else {
        FuncB(i);
    }
    FuncC(i);
}
```
这个循环重复20次，交替调用`FuncA`和`FuncB`，然后是`FuncC`。展开两个给出循环得到:  

```
// Example 7.30b
int i;
for (i = 0; i < 20; i += 2) {
    FuncA(i);
    FuncC(i);
    FuncB(i+1);
    FuncC(i+1);
}
```
这么做有三个好处：
1. `i<20`循环控制分支执行10次而不是20次。
2. 重复计数已经从20减少到10，这意味着在奔腾4上可以完美地进行预测。
3. `if`分支被消除

展开循环同样也有缺点：
1. 展开循环在代码缓存或*micro-op*缓存中占用更多空间。
2. 非常小的循环（少于65字节的代码）在Core2处理器上执行得更好。
3. 如果重复计数为奇数，并将其展开为2，则必须在循环之外执行额外的迭代。通常，当重复计数不能被展开因子整除时，就会出现这种问题。

只有在能够取得特定好处的情况下，才应该使用循环展开。如果一个循环包含浮点运算，且循环计数器是整数，那么通常可以假设整个计算时间是由浮点代码决定的，而不是由循环控制分支决定的。在这种情况下，展开循环没有任何好处。

最好避免在有*micro-op*缓存的处理器上展开循环。因为节省*mircro-op*缓存的使用非常重要。

如果有利可图的话(见72页 TODO)， 编译器通常会自动展开一个循环。程序员不必手动展开循环，除非需要获得特定的优势，例如消除示例7.30b中的`if`分支。

### <u>循环控制条件</u>

最高效的循环控制条件是一个简单的整数计数器。一个具有无序功能的微处理器（参见第105页 TODO）将能够在几个迭代之前评估循环控制语句。

如果循环控制分支依赖于循环内部的计算，则效率较低。下面的示例将以零结束的ASCII字符串转换为小写：

```
// Example 7.31a
char string[100], *p = string;
while (*p != 0)
    *(p++) |= 0x20;
```
如果字符串的长度是已知的，那么使用循环计数器会更有高效：

```
// Example 7.31b
char string[100], *p = string; int i, StringLength;
for (i = StringLength; i > 0; i--)
    *(p++) |= 0x20;
```

在数学迭代中，循环控制分支依赖于循环内部计算的是一种常见情况，如泰勒展开和牛顿-拉弗森迭代。在这里，需要重复迭代，直到残差小于一定的公差。计算残差绝对值并将其与公差进行比较所需的时间可能很长，因此确定最坏情况下的最大重复计数并始终使用此迭代次数会更高效。这种方法的优点是微处理器可以提前执行循环控制分支，并在循环内的浮点运算完成之前解决任何分支的错误预测。如果典型的重复计数接近最大重复计数，且每次迭代的残差计算对总计算时间有显著贡献，则该方法是有好处的。

循环计数器最好是整数。如果循环需要浮点计数器，那么创建一个额外的整数计数器。例如：

```
// Example 7.32a
double x, n, factorial = 1.0;
for (x = 2.0; x <= n; x++) 
    factorial *= x;
```

这可以通过添加一个整数计数器并在循环控制条件中使用整数来提升效率：

```
// Example 7.32b
double x, n, factorial = 1.0; int i;
for (i = (int)n - 2, x = 2.0; i >= 0; i--, x++) 
    factorial *= x;
```
注意带有多个计数器的循环中的逗号和分号之间的区别，如示例7.32b所示。`for`循环有三个子句：初始化、条件和增量。这三个子句用分号分隔，每个子句中的多个语句用逗号分隔。条件子句中应该只有一个语句。

将整数与零进行比较有时比将其与任何其他数字进行比较更高效。因此，将循环计数减少到0比将其增加到某个正值`n`要稍微快一些。但如果循环计数器用作数组索引，则不是这样。数据缓存是为向前而不是向后访问数组而优化的。

### <u>复制或清除数组</u>

对于诸如复制数组或将数组设置为所有零这样的琐碎任务，使用循环可能不是最佳选择。例如：

```
// Example 7.33a
const int size = 1000; int i;
float a[size], b[size];
// set a to zero
for (i = 0; i < size; i++)
    a[i] = 0.0;
// copy a to b
for (i = 0; i < size; i++)
    b[i] = a[i];
```
使用`memset`和`memcpy`函数通常会更快：

```
// Example 7.33b
const int size = 1000;
float a[size], b[size];
// set a to zero
memset(a, 0, sizeof(a));
// copy a to b
memcpy(b, a, sizeof(b));
```
至少在简单的情况下，大多数编译器会自动使用`memset`和`memcpy`的替换这些循环。显式使用`memset`和`memcpy`是不安全的，因为如果参数 size 大于目标数组的大小，可能会发生严重错误。但是如果循环计数太大，同样的错误也会发生在循环中。

## 7.14 函数
函数调用可能会使程序慢下来，原因如下：
1. 函数调用使微处理器跳转到不同的代码地址，然后再返回。这可能需要4个时钟周期。在大多数情况下，微处理器能够将调用和返回操作与其他计算重叠以节省时间。
2. 如果代码分散在内存中，那么代码缓存的效率就会降低。
3. 在32位模式下，函数参数存储在堆栈中。将参数存储在堆栈上并再次读取它们需要额外的时间。如果参数是关键依赖链的一部分，则延迟是很明显的。
4. 需要额外的时间来设置栈帧（stack frame）、保存和恢复寄存器，可能还需要保存异常处理信息。
5. 每个函数调用语句需要在分支目标缓冲区（*BTB*）中占用空间。如果程序的关键部分有许多调用和分支，*BTB*中的竞争可能导致分支错误预测。

以下方法可用于减少在程序关键部分中，在函数调用上花费的时间。

### <u>避免不必要的函数</u>

一些编程教科书建议，长度超过几行的每个函数都应该分成多个函数。我不同意这个规则。将一个函数分解成多个更小的函数只会降低程序的效率。仅仅因为一个函数很长就拆分它并不会使得程序更清晰，除非这个函数正在执行多个逻辑上不同的任务。如果可能的话，关键的最内层循环最好完全保留在一个函数中。

### <u>使用内联函数</u>

内联函数会像宏一样展开，因此调用该函数的每个语句都会被函数体替换。如果使用了`inline`关键字，或者在类定义中定义了函数的主体，那么函数通常是内联的。如果函数很小，或者只在程序中的一个位置调用它，那么内联函数是有好处的。小函数通常由编译器自动内联。另一方面，在某些情况下，如果内联会导致技术问题或性能问题，编译器可能会忽略对函数内联的请求。

### <u>避免在最内层循环中嵌套函数调用</u>

调用其他函数的函数称为帧函数（frame function），而不调用任何其他函数的函数称为叶函数（leaf function）。叶函数比框架函数更高效，原因见第63页（TODO）。如果程序关键的最内层循环包含对帧函数的调用，那么代码有可能通过内联帧函数或使帧函数调用的所有函数内联（把帧函数变为叶函数）来提升效率。

### <u>使用宏代替函数</u>

用`#define`声明的宏肯定是内联的。但是要注意，宏的参数每次使用时都会被重新计算。例如：

```
// Example 7.34a. Use macro as inline function
#define MAX(a,b) (a > b ? a : b)
y = MAX(f(x), g(x));
```
在这个例子中，`f(x)`或`g(x)`被计算两次，因为宏引用了两次。你可以通过使用内联函数而不是宏来避免这种情况。如果你想让函数可以使用任何类型的参数，那么可以使用模板：

```
// Example 7.34b. Replace macro by template
template <typename T>
static inline T max(T const & a, T const & b) {
    return a > b ? a : b;
}
```
宏的另一个问题是名称不能重载或限制作用区域。宏将干扰具有相同名称的任何函数或变量，而与作用域或命名空间无关。因此，对于宏来说，使用足够长且唯一的名称非常重要，尤其是在头文件中。

### <u>使用`fastcall`函数</u>

在32位模式下，关键字`__fastcall`将会改变函数的调用方式，使用寄存器而不是栈来传递前两个整型参数（*CodeGear*编译器则是前三个）。这可以提升拥有整型参数的函数的速度。

浮点型参数则不会被`__fastcall`影响。成员函数中隐藏的`'this'`指针也被是为一个参数，所以可能只剩下一个空闲寄存器用于传输其他参数。因此，确保在使用`__fastcall`时，最关键的整数参数放在第一位。64位模式下的函数参数默认是使用寄存器传递的。因此，64位模式下无法识别`__fastcalll`关键字。


### <u>使函数局部化</u>

在同一个模块中使用的函数（即当前.cpp文件）应该是本地的。这使得编译器使函数更容易美联，并对函数调用进行优化。有三种方法使一个函数局部化:
1. 将关键字`static`添加到函数声明中。这是最简单的方法，但它不适用于类成员函数，在类成员函数中，`static`有不同的含义。
2. 函数或类放入匿名命名空间（译者注：定义命名空间使，忽略命名空间的名称）。
3. *Gnu*编译器允许使用“__attribute__((visibility("hidden")))”

### <u>使用全程序优化</u>

一些编译器可以选择对整个程序进行优化，也可以选择将多个.cpp文件组合成一个对象文件。这使得编译器能够在组成程序的所有.cpp模块之间优化寄存器分配和参数传递。对于作为目标文件或库文件分发的函数库，不能使用全程序优化。

### <u>使用64位模式</u>

在64位模式下，参数传递比在32位模式下更高效，而64位*Linux*比64位*Windows*更快。在64位*Linux*中，前6个整数参数和前8个浮点参数使用寄存器传递，总计14个寄存器参数。而在64位*Windows*中，前四个参数在寄存器中传递，而不管它们是整数还是浮点数。因此，如果函数有四个以上的参数，64位*Linux*比64位*Windows*更快。32位*Linux*和32位*Windows*在这个层面上没有差别。

## 7.15 函数参数
在大多数情况下，函数参数是按值传递的。这意味着参数的值被复制到一个局部变量。对于`int`、`float`、`double`、`bool`、`enum`以及指针和引用等简单类型，这非常快。

数组总是使用指针传递，除非它们被打包在类或者结构体中。

如果参数是复合类型，例如结构体或类，那么情况会更复杂一些。复合类型的参数传递在符合一下几个条件的情况下是最高效的：
1.  这个对象很小，可以装入一个寄存器中。
2.  这个对象没有拷贝构造函数和析构函数。
3.  这个对象没有虚成员。
4. 这个对象没有使用运行时类型标识（*RTTI*）。

如果这些条件中，有任何一个不满足，那么使用指针或引用传递对象通常会更快。如果对象很大，那么显而易见，复制整个对象需要时间。当对象复制到参数时，必须调用复制构造函数，如果有析构函数的话，必须在函数返回之前调用析构函数。

将组合对象传递给函数的首选方法是使用`const`引用。`const`引用确保原始对象没有被修改。与指针或非`const`引用不同，`const`引用允许函数参数为表达式或匿名对象。如果函数是内联的，编译器可以很容易地优化掉const引用。

另一种解决方案是使函数成为对象的类或结构的成员，这同样有用。

在32位系统中，简单的函数参数在栈上传递，但在64位系统，使用寄存器中传递。后者效率更高。64位*Windows*允许在寄存器中传输最多4个参数。64位*Unix*系统允许在寄存器中传输最多14个参数（8个浮点数或双精度数加上6个整数、指针或引用参数）。成员函数中的`this`指针占用一个参数。手册5:“Calling conventions for different C++ compilers and operating systems”给出了更多的细节。

## 7.16 函数返回类型
函数的返回类型最好是简单类型、指针、引用或void。返回复合类型的对象更为复杂，而且常常效率低下。

复合类型的对象只能在最简单的情况下在寄存器中返回。有关何时可以在寄存器中返回对象的详细信息，请参见手册5:“Calling conventions for different C++ compilers and operating systems”。

除了最简单的情况外，复合对象的返回方式是通过一个隐藏指针将它们复制到调用方指定的位置。复制构造函数（如果有的话）通常在复制过程中被调用，而析构函数则在销毁原始构造函数时被调用。在简单的情况下，编译器可以通过在对象的最终目的地构造对象来避免对复制构造函数和析构函数的调用，但是不要依赖这一点。

你可以考虑以下替代方法，而不是返回复合对象：
1. 使函数成为对象的构造函数。
2. 让函数修改一个现有的对象，而不是创建一个新的对象。现有对象可以通过指针或引用提供给函数，或者函数可以是对象的类的成员。
3. 使函数返回一个指向函数内部定义的静态对象的指针或引用。这是有效的，但也有风险。返回的指针或引用仅在下一次调用函数并覆盖本地对象(可能在不同的线程中)之前有效。如果忘记将局部对象定义为静态的，那么一旦函数返回，它就会失效。
4. 使用`new`在函数中构造一个对象，并返回一个指向它的指针。由于动态内存分配的成本，这是低效的。如果忘记删除对象，此方法还涉及内存泄漏的风险。

## 7.17 函数尾调用
尾调用是优化函数调用的一种方法。如果函数的最后一条语句是对另一个函数的调用，那么编译器可以用跳转到第二个函数来替换该调用。编译器优化将自动完成此任务。第二个函数不会返回到第一个函数，而是直接返回第一个函数被调用的位置。这更有效效率，因为它消除了返回操作。例如：


```
// Example 7.35. Tail call
void function2(int x);
void function1(int y) {
    ...
    function2(y+1);
}

```

在这里，通过直接跳到`function2`来消除`function1`的返回。即使有返回值，也可以这样做:


```
// Example 7.36. Tail call with return value
int function2(int x);
int function1(int y) {
...
return function2(y+1);
}
```

尾调用优化只有在两个函数具有相同的返回类型时才有效。如果函数在栈上有参数（在32位模式下通常是这样），那么这两个函数必须为参数使用相同数量的栈空间。

## 7.18 递归函数
递归函数是一个调用自身的函数。函数递归调用对于处理递归数据结构非常有用。递归函数的代价是所有参数和局部变量在每次递归时都会有一个新实例，这将占用栈空间。深度递归还会降低返回地址的预测效率。这个问题通常出现在递归深度超过16的情况下（参见手册3“The microarchitecture of Intel, AMD and VIA CPUs”中对返回栈缓冲区的解释）。

递归函数调用仍然是处理分支数据树结构的最有效解决方案。较宽的树形结构比较深的树形结构，有更高的递归效率。无分支递归总是可以被循环替代，这样效率更高。递归函数的一个常见教科书例子是阶乘函数：

```
// Example 7.37. Factorial as recursive function
unsigned long int factorial(unsigned int n) {
if (n < 2) return 1;
    return n * factorial(n-1);
}
```
这种实现非常低效，因为`n`的所有实例和所有返回地址都会占用堆栈上的存储空间。使用循环更高效：

```
// Example 7.38. Factorial function as loop
unsigned long int factorial(unsigned int n) {
    unsigned long int product = 1;
    while (n > 1) {
        product *= n;
        n--;
        }
    return product;
}
```
递归尾调用（尾递归）比其他递归调用更高效，但仍然不如循环快。

初学者有时会调用`main`函数来重启程序。这不是一个好主意，因为每次递归调用`main`函数时，栈都会被所有本地变量的新实例填满。重新启动程序的正确方法是在`main`函数中使用循环。

## 7.19 结构体和类
现在，编程教科书推荐面向对象编程作为一种使软件更加清晰和模块化的方法。所谓的对象是结构和类的实例。面向对象的编程风格对程序性能既有积极的影响，也有消极的影响。积极的影响是：
1. 如果一起使用的变量是相同结构或类的成员，那么它们会被存储在一起。这使得数据缓存更有效率。
2. 不需要将类成员的变量作为参数传递给类成员函数。这些变量避免了参数传递的开销。

面向对象编程的负面影响有：
1. 非静态成员函数有一个  `this` 指针，该指针作为隐形参数传递给函数。`this` 的参数传输开销会在所有非静态成员函数上产生。
2. `this`指针占用一个寄存器。在32位系统中，寄存器是一种稀缺资源。
3. 虚成员函数的效率较低（参见第55页,TODO）。

关于面向对象编程的正面影响还是负面影响占主导地位，还没有一个通用的说法。至少，可以这样说，使用类和成员函数的代价并不大。如果面向对象的编程风格有利于程序的逻辑结构和清晰性，那么你可以使用这种风格，只要你避免在程序最关键的部分调用过多的函数。结构体的使用（没有成员函数的）对性能没有负面影响。

## 7.20 类的数据成员（变量实例）
类或结构体的数据成员是按创建类或结构实例时声明它们的顺序连续存储。将数据组织到类或结构中不存在性能损失。访问类或结构对象的数据成员所花费的时间不比访问简单变量多。

大多数编译器将数据成员对齐到整数地址以优化访问，如下表所示：

<center>

|                  Type                  |   size,bytes    | alignments, bytes |
| :------------------------------------: | :-------------: | :---------------: |
|                 `bool`                 |        1        |         1         |
|     `char`, `signed` or `unsigned`     |        1        |         1         |
|  `short int`, `signed` or `unsigned`   |        2        |         2         |
|     `int`, `signed` or `unsigned`      |        4        |         4         |
| 64-bit integer, `signed` or `unsigned` |        8        |         8         |
|   pointer or reference, 32-bit mode    |        4        |         4         |
|   pointer or reference, 64-bit mode    |        8        |         8         |
|                `float`                 |        4        |         4         |
|                `double`                |        8        |         8         |
|             `long double`              | 8, 10, 12 or 16 |      8 or 16      |

Table 7.2. Alignment of data members

</center>

这种对齐会导致结构或类中的未使用的字节空洞，这些字节的成员大小不一。例如：

```
// Example 7.39a
struct S1 {
short int a;         // 2 bytes. first byte at 0, last byte at 1
                     // 6 unused bytes
double b;            // 8 bytes. first byte at 8, last byte at 15
int d;               // 4 bytes. first byte at 16, last byte at 19
                     // 4 unused bytes
};
S1 ArrayOfStructures[100];
```
这里，`a`和`b`之间有6个未使用的字节，因为`b`必须从一个能被8整除的地址开始。最后还有4个未使用的字节。这样做的原因是，数组中`S1`的下一个实例必须从一个可被8整除的地址开始，以便将其`b`成员与8对齐。通过将最小的成员放在最后，可以将未使用的字节数减少到2：

```
// Example 7.39b
struct S1 {
double b;     // 8 bytes. first byte at 0, last byte at 7
int d;        // 4 bytes. first byte at 8, last byte at 11
short int a;  // 2 bytes. first byte at 12, last byte at 13
              // 2 unused bytes
};
S1 ArrayOfStructures[100];
```

这种重新排序使结构减少了8字节，数组占用的空间减少了800字节。

通过对数据成员的重新排序，结构体和类对象通常可以变得更小。如果类至少有一个虚成员函数，则在第一个数据成员之前或最后一个成员之后有一个指向虚拟表的指针。这个指针在32位系统中是4字节，在64位系统中是8字节。如果你对一个结构体或其每个成员的大小有疑问，那么你可以使用`sizeof`操作符进行一些测试。`sizeof`操作符返回的值包括对象末尾未使用的字节。

如果成员相对于结构体或类的开头的偏移量小于128，则访问数据成员的代码会更紧凑，因为偏移量可以表示为8位有符号数字。如果相对于结构或类的开头的偏移量是128字节或更多，那么偏移量必须表示为32位数字（在8位到32位偏移量之间，指令集没有其它可选择的偏移量）。例如：

```
// Example 7.40
class S2 {
public:
int a[100]; // 400 bytes. first byte at 0, last byte at 399
int b; // 4 bytes. first byte at 400, last byte at 403
int ReadB() {return b;}
};
```
`b`的偏移量是400。任何通过指针或成员函数（如`ReadB`）访问`b`的代码都需要将偏移量编码为32位数字。如果交换了`a`和`b`，那么可以使用一个被编码为8位有符号数字的偏移量来访问它们，或者完全不使用偏移量。这使得代码更紧凑，从而更有效地使用代码缓存。因此，建议在结构或类声明中，大数组和其他大对象放在最后，最常用的数据成员放在前面。如果不可能在前128个字节中包含所有数据成员，则将最常用的成员放在前128个字节中。

## 7.21类的成员函数（方法）
每次声明或创建类的新对象时，它都会生成数据成员的新实例。但是每个成员函数只有一个实例。函数代码不会被复制，因为相同的代码可以应用于类的所有实例。

调用成员函数与调用简单函数使用结构体（类）的指针或引用一样快。例如：

```
// Example 7.41
class S3 {
public:
int a;
int b;
int Sum1() {return a + b;}
};
int Sum2(S3 * p) {return p->a + p->b;}
int Sum3(S3 & r) {return r.a + r.b;}
```

`Sum1`, `Sum2`和`Sum3`这三个函数做的是完全一样的事情，它们的效率是一样的。如果查看编译器生成的代码，你会注意到一些编译器将为这三个函数生成完全相同的代码。`Sum1`有一个隐式的 `this` 指针，它在`Sum2`和`Sum3`中p和r的作用相同。无论你是想让函数成为类的成员，还是给它一个指向类或结构的指针或引用，都只是编程风格的问题。一些编译器通过使用寄存器中而不是栈传输 `this`，使`Sum1`在32位*Windows*中比`Sum2`和`Sum3`稍微高效一些。

静态成员函数不能访问任何非静态数据成员或非静态成员函数。静态成员函数比非静态成员函数快，因为它不需要 `this` 指针。如果成员函数不需要访问任何非静态的东西，可以通过使它们变为静态来变得更快。

## 7.22 虚成员函数
虚函数用于实现多态类。一个多态类的每个实例都有一个指针指向一个指针表（虚函数表），其中的指针指向虚函数的不同版本。这个所谓的虚函数表用于在运行时查找虚函数的正确版本。多态性是面向对象程序比非面向对象程序效率低的主要原因之一。如果可以避免使用虚函数，那么你就可以获得面向对象编程的大多数优势，而无需付出性能成本。

如果函数调用语句总是调用虚函数的相同版本，那么调用虚成员函数所花费的时间要比调用非虚成员函数多几个时钟周期。如果版本发生了变化，你可能会得到10 - 20个时钟周期的错误预测惩罚。虚函数调用的预测和错误预测规则与switch语句相同，如第44页所述（TODO）；

在对已知类型的对象调用虚函数时，可以绕过分发机制，但是不能总是依赖编译器绕过分发机制，即使很明显可以这样做。见75页（TODO）。

只有在编译时无法知道调用了多态成员函数的哪个版本时，才会需要运行时多态。如果需要在程序的关键部分中使用虚函数，那么你可以考虑是否可以在不使用多态性或使用编译时多态性的情况下完成所需的功能。

有时可以使用模板而不是虚函数来获得所需的多态性效果。模板参数应该是包含具有多个版本的函数的类。这个方法更快，因为模板参数总是在编译时解析，而不是在运行时解析。第59页（TODO）的示例7.47展示了如何做到这一点。不幸的是，它的语法非常笨拙，可能不值得花这么多功夫。

## 7.23  运行时类型识别（RTTI）
运行时类型识别会向所有类对象添加额外的信息，而且效率不高。如果编译器有*RTTI*选项，那么关闭它并使用其他实现。

## 7.24 继承
派生类的对象与包含父类和子类成员的简单类的对象的实现方法相同。父类和子类的成员访问速度相同。一般来说，您可以假设使用继承几乎没有任何性能损失。

由于如下原因代码缓存的性能可能会有轻微的下降：
1. 父类数据成员的大小被添加到子类成员的偏移量中。访问总偏移量大于127字节的数据成员的代码稍微不那么紧凑。参见54页（TODO）。
2. 父类和子类的成员函数通常存储在不同的模块中。这可能会导致大量的跳转和低效的代码缓存。这个问题可以通过确保相互调用的函数存储在彼此附近来解决。详情见第90页（TODO）。

同一个类从多个父类继承会导致成员指针和虚函数，或者通过指向基类之一的指针访问派生类对象的复杂性太高。你可以通过在派生类中创建对象来避免多重继承：

```
// Example 7.42a. Multiple inheritance
class B1; class B2;
class D : public B1, public B2 {
public:
    int c;
};
```
替换为：

```
// Example 7.42b. Alternative to multiple inheritance
class B1; class B2;
class D : public B1 {
public:
    B2 b2;
    int c;
};
```

## 7.25 构造函数和析构函数
构造函数在内部被实现为一个成员函数，该成员函数返回对对象的引用。新对象的内存分配不一定由构造函数本身完成。因此构造函数和其他成员函数效率一样。这适用于默认构造函数、复制构造函数和任何其他构造函数。

类不需要构造函数。如果对象不需要初始化，则不需要默认构造函数。如果仅通过复制所有数据成员就可以复制对象，则不需要复制构造函数。可以将简单的构造函数定义为内联的来提高性能。

无论何时通过赋值复制对象、作为函数参数或作为函数返回值，都可以调用复制构造函数。如果复制构造函数涉及内存或其他资源的分配，则它可以相当耗时。有很多方法可以避免这种浪费的内存块的复制，例如：
1. 使用对象的引用或指针，而不是复制它。
2. 使用“移动构造函数”（move constructor）来转移内存块的所有权。这需要一个支持*C++ 0x*的编译器。
3. 创建一个成员函数或友元函数或操作符，将内存块的所有权从一个对象转移到另一个对象。失去内存块所有权的对象应该将其指针设置为`NULL`。当然，应该有一个析构函数来销毁对象所拥有的任何内存块。
4. 析构函数和成员函数效率一样。如果没有必要，不要创建析构函数。虚析构函数和虚成员函数效率一样。见55页(TODO)。

## 7.26 联合体
`union`是数据成员共享相同内存空间的结构。`union`可以通过允许从不同时使用的两个数据成员共享同一块内存来节省内存空间。参见第91页的示例（TODO）。

`union`还可以用于以不同的方式访问相同的数据。例如：

```
// Example 7.43
union {
    float f;
    int i;
} x;
x.f = 2.0f;
x.i |= 0x80000000; // set sign bit of f
cout << x.f; // will give -2.0
```
在本例中，`f`的符号位是通过使用位或（`|`）运算符设置的，该运算符只能应用于整数。

## 7.27 位域
位域可能有助于使数据更加紧凑。访问位域成员不如访问结构的成员效率高。如果在大数组可以节省缓存空间或使文件更小，那么额外的时间是合理的。

使用`<<`和`|`组合操作来操作位域比单独操作成员要快。例如：

```
// Example 7.44a
struct Bitfield {
    int a:4;
    int b:2;
    int c:2;
};
Bitfield x;
int A, B, C;
x.a = A;
x.b = B;
x.c = C;
```

假设`A`、`B`、`C`的值很小，不会导致溢出，可以通过以下方式对该代码进行改善：

```
// Example 7.44b
union Bitfield {
struct {
    int a:4;
    int b:2;
    int c:2;
};
char abc;
};
Bitfield x;
int A, B, C;
x.abc = A | (B << 4) | (C << 6);
```
或者，如果需要防止溢出：

```
// Example 7.44c
x.abc = (A & 0x0F) | ((B & 3) << 4) | ((C & 3) <<6 );
```

## 7.28 重载函数
重载函数的不同版本被简单地视为不同的函数。使用重载函数没有性能损失。

## 7.29 重载操作符
重载的运算符相当于一个函数。使用重载操作符与使用具有相同功能的函数效率一样。

表达式具有多个重载操作符，将导致为中间结果创建临时对象，这可能是我们不希望看到的。例如：

```
// Example 7.45a
class vector { // 2-dimensional vector
public:
    float x, y; // x,y coordinates
    vector() {} // default constructor
    vector(float a, float b)
    {
        x = a; 
        y = b;
    } // constructor
    vector operator + (vector const & a)
    { // sum operator
        return vector(x + a.x, y + a.y);
    } // add elements
};
vector a, b, c, d;
a = b + c + d; // makes intermediate object for (b + c)
```
为中间结果（`b+c`）创建临时对象可以通过加入以下操作来避免：
```
// Example 7.45b
a.x = b.x + c.x + d.x;
a.y = b.y + c.y + d.y;
```
幸运的是，大多数编译器会在简单的情况下自动进行优化。

## 7.30 模板
模板与宏的相似之处在于，模板参数在编译之前被它们的值所替换。下面的例子说明了函数参数和模板参数之间的区别：

```
// Example 7.46
int Multiply (int x, int m) {
    return x * m;}

template <int m>
int MultiplyBy (int x) {
    return x * m;}

int a, b;
a = Multiply(10,8);
b = MultiplyBy<8>(10);
```

*a*和*b*都得到$10 * 8 = 80$。区别在于`m`传递到函数的方式。在这个简单的函数中，`m`在运行时从调用者转移到被调用的函数。但是在模板函数中，`m`在编译时被它的值所代替，这样编译器看到的是常量8而不是变量`m`。使用模板参数而不是函数参数的优点是避免了参数传递的开销。缺点是编译器需要为每个不同的值创建模板函数的新实例。如果在本例中使用许多不同的系数作为模板参数来调用`MultiplyBy`，那么代码可能会变得非常大。

在上面的例子中，模板函数比简单函数快，因为编译器知道它可以通过以为操作来实现乘以2的幂。`x*8`被`x<<3`所代替，速度更快。在简单函数的情况下，编译器不知道`m`的值，因此不能进行优化，除非函数可以内联。（在上面的例子中，编译器能够内联和优化这两个函数，并简单地将`80`存入`a`和`b`中。但在更复杂的情况下，编译器可能无法做到这一点）。

模板参数也可以是类型。第38页（TODO）的示例展示了如何使用相同的模板创建不同类型的数组。

模板是高效的，因为模板参数总是在编译时被解析。模板使源代码更加复杂，而不是编译后的代码。一般来说，使用模板在执行速度方面没有任何成本。

如果模板参数完全相同，则将两个或多个模板实例合并为一个。如果模板参数不同，那么每一组模板参数都将获得一个实例。有许多实例的模板会使编译后的代码变大，并使用更多的缓存空间。

过度使用模板会使代码难以阅读。如果模板只有一个实例，那么你也可以使用`#define`、`const`或`typedef`来代替模板参数。

模板可以用于元编程，如第154页所述(TODO)；

### <u>使用模板实现多态</u>
模板类可用于实现编译时多态性，这比使用虚拟成员函数获得的运行时多态性更加高效。下面的示例首先展示了运行时多态性：

```
// Example 7.47a. Runtime polymorphism with virtual functions
class CHello {
public:
    void NotPolymorphic(); // Non-polymorphic functions go here
    virtual void Disp(); // Virtual function
    void Hello() {
        cout << "Hello ";
        Disp(); // Call to virtual function
    }
};
class C1 : public CHello {
public:
    virtual void Disp() {
        cout << 1;
    }
};
class C2 : public CHello {
public:
    virtual void Disp() {
        cout << 2;
    }
};
void test () {
    C1 Object1; C2 Object2;
    CHello * p;
    p = &Object1;
    p->NotPolymorphic(); // Called directly
    p->Hello(); // Writes "Hello 1"
    p = &Object2;
    p->Hello(); // Writes "Hello 2"
}
```

如果编译器不知道对象`p`指向什么类（参见第75页，TODO），则会在运行时分发到`C1::Disp()`或`C2::Disp()`。当前的编译器不太擅长优化掉`p`，并内联`Object1.Hello()`的调用，不过将来的编译器可能能够做到这一点。

如果在编译时知道对象是属于类`C1`还是`C2`，那么我们就可以避免低效的虚函数分发过程。这可以通过在活动模板库（*ATL*）和Windows模板库（*WTL*）中使用的特殊技巧来实现：

```
// Example 7.47b. Compile-time polymorphism with templates
// Place non-polymorphic functions in the grandparent class:
class CGrandParent {
public:
    void NotPolymorphic();
};
// Any function that needs to call a polymorphic function goes in the
// parent class. The child class is given as a template parameter:
template <typename MyChild>
class CParent : public CGrandParent {
public:
void Hello() {
    cout << "Hello ";
    // call polymorphic child function:
    (static_cast<MyChild*>(this))->Disp();
    }
};
// The child classes implement the functions that have multiple
// versions:
class CChild1 : public CParent<CChild1> {
public:
    void Disp() {
        cout << 1;
    }
};
class CChild2 : public CParent<CChild2> {
public:
    void Disp() {
        cout << 2;
    }
};
void test () {
    CChild1 Object1; CChild2 Object2;
    CChild1 * p1;
    p1 = &Object1;
    p1->Hello(); // Writes "Hello 1"
    CChild2 * p2;
    p2 = &Object2;
    p2->Hello(); // Writes "Hello 2"
}
```
在这里`CParent`是一个模板类，它通过模板参数获取关于其子类的信息。它可以通过将它的 `this` 指针类型转换为指向它的子类的指针来调用它的子类的多态成员。只有将正确的子类名作为模板参数时，这才是安全的。换句话说，您必须确保子类的声明 `class CChild1 : public CParent<CChild1> {`和模板参数具有相同的名称。

现在继承的顺序如下。第一代类（`CGrandParent`）包含任何非多态成员函数。第二代类（`CParent<>`）包含任何需要调用多态函数的成员函数。第三代类包含多态函数的不同版本。第二代类可以通过模板参数获取关于第三代类的信息。the user might experience unacceptably long response
times to keyboard and mouse inputs when the program is busy doing the spell checking.

如果对象的类名是已知的，那么在将运行时分派虚成员函数时不会浪费时间。这些信息包含在具有不同类型的`p1`和`p2`中。缺点是`CParent::Hello()`有多个实例占用缓存空间。

例7.47b中的语法显然是非常笨拙的。通过避免虚函数分发机制，我们节省出来的几个时钟周期，难以证明如此复杂的难以理解的，因此也难以维护的代码是合适的。如果编译器能够自动执行反虚化（参见第75页，TODO），那么依赖编译器优化肯定比使用这种复杂的模板方法更加方便。

## 7.31 线程
线程用于同时或看起来是同时地执行两个或多个作业。如果计算机只有一个*CPU*核心，那么不可能同时执行两个任务。对于前台任务，每个线程将获得通常为30 ms的时间片，对于后台任务，每个线程将获得10 ms的时间片。每个时间片之后的上下文切换非常耗时，因为所有缓存都必须适应新的上下文。可以通过设置更长的时间片来减少上下文切换的次数。这将使应用程序运行得更快，但用户输入的响应时间会更长。(在*Windows*中，你可以通过在高级系统性能选项下为后台服务选择优化性能，将时间片增加到120ms。我不知道这在*Linux*中是否可行)。

为不同的任务的不同线程分配不同的优先级是非常有用的。例如，在字处理软件中，用户希望按下一个按键或移动鼠标时能够立即得到响应，这项任务必须有很高的优先级。而其他任务，例如拼写检查和重新分页，在其他优先级较低的线程中运行。如果不同的任务没有被划分成具有不同优先级的线程，那么当程序忙于拼写检查时，可能需要花很长时间来响应键盘和鼠标输入，这是用户所不希望遇到的。

如果应用程序有图形用户界面，那么任何需要很长时间的任务，比如繁重的数学计算，都应该安排在单独的线程中。否则程序将无法快速响应键盘或鼠标输入。

在应用程序中执行类似线程的调度而不调用操作系统线程调度程序，以节省开销是可能的。这可以通过在图形用户界面（在*Windows*  *MFC*中为`OnIdle`）的消息循环中调用的函数中逐块地进行大量的后台计算来实现。这种方法可能比在只有一个*CPU*内核的系统中创建单独的线程要快，但是它要求后台作业可以被分割成合适持续时间的多个小块。

充分利用具有多个*CPU*内核的系统的最佳方法是将工作划分为多个线程。然后每个线程可以在自己的*CPU*内核上运行。

在优化多线程应用程序时，我们必须考虑多线程的四种成本：
1. 启动和停止线程的成本。如果与启动和停止线程所需的时间相比，任务的持续时间较短，则不要将其放入单独的线程中。
2. 任务切换的成本。如果具有相同优先级的线程数量不超过*CPU*内核的数量，则此成本达到最小值。
3. 线程间同步和通信的成本。信号量、互斥量等的开销相当大。如果两个线程经常为了访问同一资源而相互等待，那么最好将它们合并到一个线程中。多个线程之间共享的变量必须声明为`volatile`。这将阻止编译器对该变量进行优化。
4. 不同的线程需要单独的存储空间。多线程使用的函数或类都不应该依赖于静态变量或全局变量。(参见线程本地存储p.28，TODO）。线程有各自的堆栈。如果线程共享相同的缓存，这可能会导致缓存竞争。

多线程程序必须使用线程安全的函数。线程安全的函数永远不应该使用静态变量。

有关多线程技术的进一步讨论，请参见第10章第103页（TODO）。

## 7.32 异常和错误处理
运行时错误会导致异常，这些异常可以通过陷阱（traps）或软件中断的形式检测到。可以使用`try-catch`块捕捉这些异常。如果启用异常处理且没有try-catch块，则程序将崩溃，并显示错误消息。

异常处理旨在检测很少发生的错误，并以一种优雅的方式从错误条件中恢复。你可能认为只要没有发生错误，异常处理就不需要额外的时间，但不幸的是，这并不总是正确的。为了知道如何在异常事件中恢复，程序可能需要做大量的记录工作。这种记录的消耗在很大程度上取决于编译器。有些编译器具有高效的基于表的方法，开销很少或没有，而其他编译器则具有低效的基于代码的方法，或者需要运行时类型标识（*RTTI*），这会影响代码的其他部分。更详细的信息请参阅[ ISO/IEC TR18015 Technical Report on C++ Performance ](http://www.open-std.org/jtc1/sc22/wg21/docs/TR18015.pdf)。

下面的例子解释了为什么需要记录工作：

```
// Example 7.48
class C1 {
public:
    ...
    ~C1();
};

void F1() {
    C1 x;
    ...
}
void F0() {
    try {
        F1();
    }
    catch (...) {
        ...
    }
}
```
函数`F1`在返回时应该调用对象`x`的析构函数。但是如果`F1`中的某个地方发生异常怎么办？然后我们跳出`F1`而不返回。`F1`的清理工作被阻止了，因为它被中断了。现在，异常处理程序负责调用`x`的析构函数，这只有在`F1`保存了要调用的析构函数的所有信息或可能需要的任何其他清理信息时才有可能。如果`F1`调用另一个函数进而调用另一个函数，等等，如果在最里面的函数产生了一个异常，然后异常处理程序需要关于函数调用链和需要遵循的函数调用的顺序等所有信息，来检查所有必要的清理工作。这叫做堆栈展开。

即使没有异常发生，所有函数仍必须为异常处理程序保存一些信息。这就是异常处理在某些编译器中代价高昂的原因。如果你的应用程序不需要异常处理，那么应该禁用它，以便使代码更小、更高效。你可以通过关闭编译器中的异常处理选项来禁用整个程序的异常处理。你也可以通过向函数原型中添加`throw()`来禁用单个函数的异常处理：

```
void F1() throw();
```

这允许编译器假设`F1`永远不会抛出任何异常，这样它就不必为函数`F1`保存恢复信息。但是，如果`F1`调用另一个可能抛出异常的函数`F2`，那么`F1`必须检查`F2`抛出的异常，并在`F2`实际抛出异常时调用`std::unexpected()`函数。因此，只有当F1调用的所有函数也有一个`throw()`声明时才可以对`F1`使用`throw()`声明。`throw()`声明对于库函数很有用。

编译器会区分叶函数和帧函数。帧函数是至少调用一个其他函数的函数。叶函数是一个不调用任何其他函数的函数。叶函数比帧函数简单，因为如果可以排除异常，或者在发生异常时没有什么需要清理的情况下，堆栈展开信息可以被忽略。帧函数可以通过内联它调用的所有函数来转换为叶函数。如果程序最内层的关键循环不包含对帧函数的调用，则可以得到最佳性能。

虽然`throw()`语句在某些情况下可以提升、优化程序性能，但是没有理由添加诸如`throw(A,B,C)`这样的语句来显式地告诉函数可以抛出什么样的异常。实际上，编译器可能会添加额外的代码来检查抛出的异常是否属于指定的类型（参见Sutter的文章：[A Pragmatic Look at Exception Specifications, Dr Dobbs Journal, 2002](http://www.drdobbs.com/sutters-mill-a-pragmatic-look-at-except/184401544)）。

在某些情况下，即使在程序最关键的部分使用异常处理也是最优的。如果替代实现的效率较低，并且您希望能够从错误中恢复，那么就会出现这种情况。下面的示例演示了这种情况：

```
// Example 7.49
// Portability note: This example is specific to Microsoft compilers.
// It will look different in other compilers.
#include <excpt.h>
#include <float.h>
#include <math.h>
#define EXCEPTION_FLT_OVERFLOW 0xC0000091L

void MathLoop()
{
    const int arraysize = 1000; unsigned int dummy;
    double a[arraysize], b[arraysize], c[arraysize];
    // Enable exception for floating point overflow:
    _controlfp_s(&dummy, 0, _EM_OVERFLOW);
    //_controlfp(0, _EM_OVERFLOW); // if above line doesn't work
    int i = 0; // Initialize loop counter outside both loops
    // The purpose of the while loop is to resume after exceptions:
    while (i < arraysize)
    {
        // Catch exceptions in this block:
        __try
        {
            // Main loop for calculations:
            for ( ; i < arraysize; i++)
            {
                // Overflow may occur in multiplication here:
                a[i] = log (b[i] * c[i]);
            }
        }
        // Catch floating point overflow but no other exceptions:
        __except (GetExceptionCode() == EXCEPTION_FLT_OVERFLOW
        ? EXCEPTION_EXECUTE_HANDLER : EXCEPTION_CONTINUE_SEARCH)
        {
            // Floating point overflow has occurred.
            // Reset floating point status:
            _fpreset();
            _controlfp_s(&dummy, 0, _EM_OVERFLOW);
            // _controlfp(0, _EM_OVERFLOW); // if above doesn't work
            // Re-do the calculation in a way that avoids overflow:
            a[i] = log(b[i]) + log(c[i]);
            // Increment loop counter and go back into the for-loop:
            i++;
        }
    }
}
```

假设`b[i]`和`c[i]`中的数字非常大，以至于在乘法`b[i]*c[i]`中可以发生溢出，尽管这种情况很少发生。上面的代码将捕获溢出时的异常，并以一种花费更多时间但避免溢出的方式重新执行计算。对每个因子取对数，而不是对乘积取对数，可以确保不会发生溢出，但是计算时间增加了一倍。

支持异常处理所需的时间可以忽略不计，因为在关键的最内层循环中没有`try`块或函数调用（日志除外）。`log`是一个库函数，我们假设它是经过优化的。无论如何，我们都不能更改其可能的异常处理支持。异常发生时代价很高，但这不是问题，因为我们假设这种情况很少发生。

在这里，测试循环内部的溢出条件不需要任何成本，因为我们依赖微处理器硬件在发生溢出时引发异常。异常被操作系统捕获，如果有`try`块，操作系统会将其重定向到程序中的异常处理程序。

捕获硬件异常存在可移植性问题。这种机制依赖于编译器、操作系统和`CPU`硬件中的非标准化细节。将这样的应用程序移植到不同的平台可能需要修改代码。

让我们在这个例子中看看异常处理的可能替代方法。在相乘之前，我们可以检查`b[i]`和`c[i]`是否太大，从而检查溢出。这将需要两个浮点数比较，这是比较耗时的，因为它们必须在最内层循环中。另一种可能是始终使用安全的公式`a[i] = log(b[i]) + log(c[i])`，这将使`log`的调用次数增加一倍，而对数需要很长时间来计算。如果有一种方法可以在不检查所有数组元素的情况下检查循环之外的溢出，那么这可能是一种更好的解决方案。如果所有因子都是由相同的几个参数生成的，那么在循环之前进行这样的检查是可能的。或者，如果结果由某些公式组合成单个结果，那么可以在循环之后进行检查。

### <u>异常和向量代码</u>
向量指令对于并行执行多个计算是有用的。下文第12章对此进行了描述。异常处理不适用于向量代码，因为向量中的单个元素可能会导致异常，而其他向量元素可能不会。由于分支在向量代码中实现的方式，你甚至可以在未采用的分支中得到异常。如果代码可以从向量指令中获益，那么最好禁用异常捕获，转而依赖`NAN`和`INF`的传递。见下文第7.34章。关于这一点进一步讨论参见[www.agner.org/optimize/nan_propagation.pdf](www.agner.org/optimize/nan_propagation.pdf)。

### <u>避免异常处理的成本</u>
当不需要尝试从错误中恢复时，不需要异常处理。如果你只是希望程序发出错误消息并在出现错误时停止程序，那么就没有理由使用`try`、`catch`和`throw`。更好的方法是定义自己的错误处理函数，该函数只打印适当的错误消息，然后调用`exit`。

如果有已分配的资源需要被清理的话， 调用`exit`可能并不安全，解释如下。还有其他不使用异常处理错误的可能方法。检测错误的函数可以返回一个错误代码，调用函数可以使用该代码进行恢复或发出错误消息。

建议使用系统的、经过深思熟虑的方法来处理错误。你必须区分可恢复错误和不可恢复错误；确保分配的资源在发生错误时得到清理；并向用户发送适当的错误消息。

### <u>编写异常安全代码</u>
假设一个函数以独占模式打开一个文件，并且在文件关闭之前有一个错误条件终止了程序。程序被终止之后，该文件将保持锁定后，用户将无法访问该文件，直到计算机重新启动。为了防止这类问题，你必须使您的程序异常安全。换句话说，程序必须在异常或其他错误情况下清理所有东西。可能需要清理的东西包括：
1. 使用`new`或者`malloc`分配的内存。
2. 窗口、图形画刷等的句柄。
3. 锁定的互斥量。
4. 打开的数据库连接。
5. 打开的文件和网络连接。
6. 需要被删除的临时文件。
7. 需要保存的用户工作。
8. 任何其它已分配的资源。

*C++*处理清理工作的方法是创建一个析构函数。可以将读取或写入文件的函数包装到具有确保文件关闭的析构函数的类中。相同的方法可以用于任何其他资源，例如动态分配的内存、窗口、互斥量、数据库连接等等。

*C++*异常处理系统确保调用本地对象的所有析构函数。如果包装器类有析构函数来处理分配资源的所有清理工作，则程序是异常安全的。如果析构函数引发另一个异常，则系统可能会出现问题。

如果你使用自己的错误处理系统而不是使用异常处理，那么你无法确保调用了所有析构函数并清理了资源。如果错误处理程序调用`exit()`、`abort()`、`_endthread()`等，则不能保证所有析构函数被调用。在不使用异常的情况下处理不可恢复错误的安全方法是从函数返回。如果可能，函数可能返回错误代码，或者错误代码可能存储在全局对象中。然后调用函数必须检查错误代码。如果后者也需要清理，那么它必须返回给自己的调用者，依此类推。

## 7.33 堆栈展开的其它情况
前面一节描述了一种称为堆栈展开的机制，异常处理程序使用这种机制清理和调用任何必要的析构函数，这些析构函数在出现异常时跳出函数，而不使用正常的返回路径。这种机制也适用于其他两种情况：

当线程终止时，可以使用堆栈展开机制。目的是检测线程中声明的任何对象是否具有需要调用的析构函数。建议在结束线程之前从需要清理的函数返回。你不能确保对`_endthread()`的调用会清除堆栈。这种行为依赖于具体的实现。

当使用`longjmp`函数从函数中跳出时，也使用堆栈展开机制。如果可能，避免使用`longjmp`。在时间相当重要的代码中不要依赖`longjmp`。

## 7.34 `NAN`和`INF`的传递

在大多数情况下，浮点错误会传播到一系列计算的最终结果。这是异常和错误捕获的一种非常有效的替代方法。

浮点溢出和除以0得到无穷大。如果你把无穷大和某数相加或相乘，结果就是无穷大。`INF`代码可以以这种方式传播到最终结果。然而，并不是所有使用`INF`输入的操作都会得到`INF`。如果用一个正常的数字除以`INF`，会得到0。特殊情况`INF-INF`和`INF/INF`得到`NAN` （not-a-number）。当你用0除以0以及函数的输入超出范围时，比如`sqrt(-1)`和`log(-1)`，也会出现特殊的代码`NAN`。

使用`NAN`作为输入的大多数操作将输出`NAN`，因此`NAN`将传播到最终结果。这是一种简单有效的浮点错误检测方法。几乎所有以`INF`或`NAN`形式出现的浮点错误都将传播到它们最终结果。如果打印结果，你将看到`INF`或`NAN`，而不是数字。跟踪错误不需要额外的代码，`INF`和`NAN`的传播也不需要额外的成本。

`NAN`可以包含带有额外信息的负载（payload）。函数库可以在出现错误时将错误代码放入此负载中，此负载将传播到最终的结果。

当参数为`INF`或`NAN`时，函数`finite()`将返回`false`，如果它是一个普通的浮点数，则返回`true`。这可用于在浮点数转换为整数之前检测错误，以及在其他需要检查错误的情况下。

`INF`和`NAN`传播的详细信息请参阅[NAN propagation versus fault trapping in floating point code](www.agner.org/optimize/nan_propagation.pdf)。该手册还讨论了`INF`和`NAN`的传递失败的情况，以及影响这些代码传递的编译器优化选项。

## 7.35 预处理命令
就程序性能而言，预处理指令（以`#`开头的所有指令）的性能成本很少，因为它们在程序编译之前就已经解析了。

`#if`指令对于支持多个平台或使用相同源代码的多个配置是很有用的。`#if`比`if`更高效，因为`#if`是在编译时解析的，而`if`是在运行时解析的。

当用于定义常量时，`#define`指令等价于`const`定义。例如，`#define ABC 123` 和 `const int ABC = 123`的效率相同的，因为在大多数情况下，编译器优化可以用它的值替换整数常量。然而，`const int`声明在某些情况下可能占用内存空间，而`#define`指令从来不占用内存空间。浮点常量总是占用内存空间，即使没有给它命名。

当作为宏使用时，`#define`指令有时比函数更高效。参见第48页（TODO）的讨论。

## 7.36 命名空间
使用名称空间，对执行速度没有影响。

# 8 编译器中的优化

## 8.1 编译器时如何优化的
现代编译器为了提高性能，会对代码进行大量修改。程序员知道编译器能做什么和不能做什么是很有用的。下面几节描述了一些编译器的优化，这些优化是程序员需要了解的。

### <u>函数内联</u>
编译器可以用被调用函数的主体替换函数调用。例如：

```
// Example 8.1a
float square (float a)
{
    return a * a;
}

float parabola (float x) 
{
    return square(x) + 1.0f;
}
```
编译器可以将对`square`的调用替换为`square`内部的代码：

```
// Example 8.1b
float parabola (float x)
{
    return x * x + 1.0f;
}
```
函数内联的优点是：
1. 节约了调用、返回和参数传递的开销
2. 因为代码变得连续了，代码缓存的效率会更高，
3. 如果只调用一次内联函数，那么代码就会变得更小。
4. 函数内联可以使其他优化的成为可能，如下所述。

函数内联的缺点是：如果对内联函数有多个调用且函数体很大，则代码会变得更大。 如果函数很小，或者只从一个或几个地方调用它，那么编译器更可能使函数内联。

### <u>常量折叠和常数传播</u>
只包含常量的表达式或子表达式将被计算结果替换。例如：

```
// Example 8.2a
double a, b;
a = b + 2.0 / 3.0;
```
编译器将会替换成下面的代码：

```
// Example 8.2b
a = b + 0.666666666666666666667;
```
这其实很方便，使用`2.0/3.0`要比计算值并使用许多小数要来的容易。建议为这样的子表达式加上括号，以确保编译器将其识别为子表达式。例如，`b*2.0/3.0`将识别为`(b*2.0)/3.0`，而不是`b*(2.0/3.0)`，除非为常量子表达加上括号。

常量可以通过一系列的计算来传播：

```
// Example 8.3a
float parabola (float x) 
{
    return x * x + 1.0f;
}
float a, b;
a = parabola (2.0f);
b = a + 1.0f;
```
有可能被编译器替换成：

```
// Example 8.3b
a = 5.0f;
b = 6.0f;
```
当表达式包含不能被内联的函数或者不能再编译时期计算的时候，常量折叠和常量传播就不可能起作用。例如：

```
// Example 8.4
double a = sin(0.8);
```
`sin`函数是在一个单独的函数库中定义的，不能期望编译器能够内联这个函数并在编译时计算它。一些编译器能够在编译时计算最常见的数学函数，如`sqrt`和`pow`，但不能计算更复杂的函数，比如`sin`。

### <u>消除指针</u>
如果指向的目标已知，则可以消除指针或引用。例如：

```
// Example 8.5a
void Plus2 (int * p) 
{
    *p = *p + 2;
}
int a;
Plus2 (&a);
```
可能被编译器替换成：

```
// Example 8.5b
a += 2;
```

### <u>消除公共子表达式</u>
如果相同的子表达式出现多次，那么编译器可能只计算一次。例如：

```
// Example 8.6a
int a, b, c;
b = (a+1) * (a+1);
c = (a+1) / 4;
```
可能被编译器替换成：

```
// Example 8.6b
int a, b, c, temp;
temp = a+1;
b = temp * temp;
c = temp / 4;
```

### <u>寄存器变量</u>
最常用的变量存储被在寄存器中（参见第27页，TODO）。

再32为系统中，整数寄存器变量的最大数量大约是6个，在64位系统中大约是14个。

在32位系统中，浮点寄存器变量的最大数量为8个，在64位系统中为16个。一些编译器很难在32位系统中生成浮点寄存器变量，除非启用了*SSE2*（或更高版本）指令集。

编译器将为寄存器变量选择最常用的变量。这包括指针和引用，它们可以存储在整数寄存器中。寄存器变量的典型候选对象是临时中间变量、循环计数器、函数参数、指针、引用、`this`指针、公共子表达式和归纳变量（见下文）。

如果一个变量的地址被取走，也就是说，如果有指向它的指针或引用，那么这个变量就不能存储在寄存器中。因此，对于可能受益于寄存器存储的变量，你应该避免使任何指针或引用。

### <u>活动范围分析</u>
变量的活动范围是指变量被使用的代码范围。对于活动范围不重叠的变量，编译器优化可以使用相同的寄存器。这在可用寄存器数量有限的时候是非常有用的。例如：

```
// Example 8.7
int SomeFunction (int a, int x[])
{
    int b, c;
    x[0] = a;
    b = a + 1;
    x[1] = b;
    c = b + 1;
    return c;
}
```
在本例中，`a`、`b`和`c`可以共享同一个寄存器，因为它们的活动范围不重叠。如果`c = b + 1`更改为`c = a + 2`，那么`a`和`b`就不能使用相同的寄存器，因为它们的活动范围现在发生重叠了。

编译器通常不会将此原则用于存储在内存中的对象。它不会为不同的对象使用相同的内存区域，即使它们的活动范围不重叠。有关如何使不同的对象共享相同的内存区域的示例，请参见第91页（TODO）。

### <u>合并相同的分支</u>
通过合并相同的代码片段，可以使代码更加紧凑。例如：

```
// Example 8.8a
double x, y, z; bool b;
if (b)
{
    y = sin(x);
    z = y + 1.;
}
else
{
    y = cos(x);
    z = y + 1.;
}
```
可能被编译器替换为：

```
// Example 8.8b
double x, y; bool b;
if (b)
{
    y = sin(x);
}
else
{
    y = cos(x);
}
z = y + 1.;
```

### <u>消除跳转</u>
可以通过复制它跳转到的代码来避免跳转。例如：

```
int SomeFunction (int a, bool b)
{
    if (b)
    {
        a = a * 2;
    }
    else
    {
        a = a * 3;
    }
    return a + 1;
}
```
这段代码从`a=a*2`跳转到`return a+1;`,。编译器可以通过复制`return`语句来消除这个跳转：

```
// Example 8.9b
int SomeFunction (int a, bool b)
{
    if (b)
    {
        a = a * 2;
        return a + 1;
    }
    else
    {
        a = a * 3;
        return a + 1;
    }
}
```
如果条件可以被简化为永远为真或永远为假，则可以消除分支：

```
// Example 8.10a
if (true)
{
    a = b;
}
else
{
    a = c;
}
```
可以被简化为：

```
// Example 8.10b
a = b;
```
如果可以从前一个分支知道某个分支的情况，那么也可以删除该分支。例如：

```
// Example 8.11a
int SomeFunction (int a, bool b)
{
    if (b)
    {
        a = a * 2;
    }
    else
    {
        a = a * 3;
    }
    if (b)
    {
        return a + 1;
    }
    else
    {
        return a - 1;
    }
}
```
编译器可能会把这个简化成：

```
// Example 8.11b
int SomeFunction (int a, bool b) 
{
    if (b)
    {
        a = a * 2;
        return a + 1;
    }
    else
    {
        a = a * 3;
        return a - 1;72
    }
}
```

### <u>循环展开</u>
如果需要高度优化，一些编译器将展开循环。见45页(TODO)。如果循环体非常小，或者它为进一步优化提供了可能性，那么这可能是有利的。重复计数非常小的循环可以完全展开，以避免循环开销。例如：

```
// Example 8.12a
int i, a[2];
for (i = 0; i < 2; i++)
    a[i] = i+1;
```
编译器可能会把这个简化成：

```
// Example 8.12b
int a[2];
a[0] = 1;
a[1] = 2;
```
不幸的是，一些编译器展开太多。过多的循环展开不是最优的，因为它会占用太多的代码缓存空间，并且会填满某些微处理器的循环缓冲区。在某些情况下，关闭编译器中的循环展开选项是有用的。

### <u>移动循环中的不变代码</u>
如果计算独立于循环计数器，则可以将其移出循环。例如：

```
// Example 8.13a
int i, a[100], b;
for (i = 0; i < 100; i++) 
{
    a[i] = b * b + 1;
}
```
可能会被编译器改成这样：

```
// Example 8.13b
int i, a[100], b, temp;
temp = b * b + 1;
for (i = 0; i < 100; i++)
{
    a[i] = temp;
}
```

### <u>归纳变量（Induction variables）</u>
循环计数器的线性函数表达式可以通过在前一个值上添加一个常数来计算。例如：

```
// Example 8.14a
int i, a[100];
for (i = 0; i < 100; i++)
{
    a[i] = i * 9 + 3;
}
```
编译器可能会将其改成下面的形式以避免乘法：

```
// Example 8.14b
int i, a[100], temp;
temp = 3;
for (i = 0; i < 100; i++)
{
    a[i] = temp;
    temp += 9;
}
```
归纳变量常用于计算数组元素的地址。例如：

```
// Example 8.15a
struct S1 {double a; double b;};
S1 list[100]; int i;
for (i = 0; i < 100; i++)
{
    list[i].a = 1.0;
    list[i].b = 2.0;
}
```
为了访问`list`的元素，编译器必须计算它的地址。`list[i]`的地址等于`list`的起始地址加上`i*sizeof(S1)`。这是一个关于`i`的线性函数，这是可以通过归纳变量计算的。编译器可以使用相同的归纳变量来访问`list[i].a`和`list[i].b`。当可以提前计算归纳变量的最终值时，也可以消去`i`，用归纳变量作为循环计数器。这可以将代码简化为：

```
// Example 8.15b
struct S1 {double a; double b;};
S1 list[100], *temp;
for (temp = &list[0]; temp < &list[100]; temp++)
{
    temp->a = 1.0;
    temp->b = 2.0;
}
```
因子`sizeof(S1) = 16`实际上隐藏在示例8.15b中的*C++*语法后面。`& 8list[100]`的整数表示形式为`(int)(&list[100]) = (int)(&list[0]) + 100*16`，而`temp++`实际上是在`temp`的整数值上加上16。

编译器不需要归纳变量来计算简单类型的数组元素的地址，因为CPU有硬件支持计算一个数组元素的地址，如果地址可以表示为一个基地址加上一个常数加上索引乘以一个系数1，2，4或8,但不是任何其他因数。如果在例 8.15a中的`a`和`b`是`float`而不是`double`，那么`sizeof(S1)`的值将是8，那么就不需要归纳变量了，因为CPU有硬件支持 index乘上8。

我研究的编译器不为浮点表达式或更复杂的整数表达式生成归纳变量。有关如何使用归纳变量计算多项式的示例，请参见第81页（TODO）。

### <u>调度</u>
编译器可以为了并行执行对指令重新排序。例如：

```
// Example 8.16
float a, b, c, d, e, f, x, y;
x = a + b + c;
y = d + e + f;

```
在这个例子中，编译器可以交错这两个公式,先算`a + b`，然后是`d + e`，然后将`c`加到第一个和中，那么`f`被加到第二个和中，第一个结果是存储在`x`中，最后第二个结果存储在`y`中。这样做的目的是帮助*CPU*实现多个并行计算。现代*CPU*实际上可以在没有编译器帮助的情况下对指令进行重新排序（参见第105页，TODO），但是编译器可以使*CPU*更容易地对指令进行重新排序。

### <u>代数约简</u>
多数编译器可以使用代数的基本定律来约简简单的代数表达式。例如，编译器可以将表达式`-(-a)`更改为`a`。

我不认为程序员会经常写出像`-(-a)`这样的表达式，但是这种表达式可能是其他优化（如函数内联）的结果。可约表达式也经常作为宏展开的结果出现。

然而，程序员经常编写可以约简的表达式。这可能是因为未约简的表达式更好地解释了程序背后的逻辑，或者因为程序员没有考虑代数约简的可能性。例如，程序员可能更喜欢使用`if(!a && !b) `而不是同等的`if(!(a || b))`即使后者少一个运算符。幸运的是，在这种情况下，所有编译器都能够进行约简。

你不能指望编译器约简复杂的代数表达式。例如，在我测试的编译器中，只有一个编译器能够将`(a*b*c)+(c*b*a)`约简为`a*b*c*2`。在编译器中实现很多代数规则是相当困难的。一些编译器可以约简某些类型的表达式，而另一些编译器可以约简其他类型的表达式，但我所见过的编译器不能都约简它们。在布尔代数中，可以实现一种通用算法（例如，Quine-McCluskey或者Espresso）来约简任何表达式，但我测试过的编译器似乎都没有这样做。

编译器在约简整数表达式上比浮点表达式做得更好，尽管这两种情况下的代数规则是相同的。这是因为浮点表达式的代数操作可能会产生不希望的效果。这种效果可以用下面的例子来说明：

```
// Example 8.17
char a = -100, b = 100, c = 100, y;
y = a + b + c;
```

这里`y`的值是$-100+100+100 = 100$。现在，根据代数规则，我们可以这样写：

```
y = c + b + a;
```
如果子表达式`c+b`可以在其他地方重用，那么这可能很有用。在这个例子中，我们使用的是8位整数，范围从-128到+127。整数溢出将使值反转（wrap around）。127加1等于-128，减1等于-128。计算`c+b`会产生溢出，结果是`-56`而不是`200`。接下来，我们将`-100`加到`-56`中，这将产生一个下溢，得到`100`，而不是`-156`。令人惊讶的是，我们得到了正确的结果，因为上溢和下溢相互抵消了。这就是为什么对整数表达式使用代数操作是安全的（除了`<`、`<=`、`>`和`>=`操作符）。

同样的讨论不适用于浮点表达式。浮点变量在上溢和下溢时，不会反转。浮点变量的范围非常大，除了在特殊的数学应用中，我们不必太担心上溢和下溢。但是我们必须担心精度的损失。让我们用浮点数重复上面的例子：

```
// Example 8.18
float a = -1.0E8, b = 1.0E8, c = 1.23456, y;
y = a + b + c;
```
这里的计算结果先得出`a+b=0`，然后`0+1.23456 = 1.23456`。但是如果我们改变操作数的顺序，先加上`b`和`c`，就不会得到相同的结果。`b + c = 100000001.23456`。浮点类型的精度大约为7位有效数字，因此b+c的值四舍五入为100000000。把`a`加到这个数上得到`0`，而不是`1.23456`。

这里讨论的结果是，改变浮点操作数的顺序，就有丢失精度的风险。除非你指定一个允许不需要精确的浮点运算的选项，否则编译器不会这么做。即使打开了所有相关的优化选项，编译器也不会执行诸如`0/a = 0`这样的明显简化，因为如果`a`为0、无穷大或`NAN`（不是一个数字），这将是无效的。不同的编译器的行为不同，因为对于哪些不精确应该允许，哪些不允许，存在不同的观点。

不能依赖编译器对浮点代码执行任何代数消减，只能依赖于对整数代码进行最简单的缩减。手动消减会更安全。我测试了在7个不同的编译器，简化各种代数表达式的能力。结果如下表8.1所示。

### <u>实体化（Devirtualization）</u>
如果知道所需要虚函数的个版本，编译器优化可以绕过虚拟表查找，直接调用虚拟函数。例如：

```
// Example 8.19. Devirtualization
class C0
{
public:
    virtual void f();
};
class C1 : public C0
{
public:
    virtual void f();
};
void g()
{
    C1 obj1;
    C0 * p = & obj1;
    p->f(); // Virtual call to C1::f
}
```

如果不进行优化，编译器需要在虚拟表中查找`p->f(`)调用是否转到`C0::f`或`C1::f`。但是编译器优化将看到`p`总是指向类`C1`的对象，因此它可以直接调用`C1::f`，而不使用虚拟表。不幸的是，很少有编译器能够进行这种优化。

# 8.2 不同编译器的对比

我在9种不同的*C++*编译器上做了一系列的实验，看看它们是否能够进行不同种类的优化。结果见表8.1。该表显示了不同的编译器是否成功地在我的测试示例中应用了各种优化方法和代数约简。

该表可以提供一些指导，说明你可以期望特定的编译器获得哪些优化，以及必须手动进行哪些优化。

必须强调的是，编译器在不同的测试示例上可能有不同的行为。你不能期望编译器总是根据表格的结果来运行。
<center>

|                 **Optimization method**                 | **Microsoft** | **Borland** | **Intel** | **Gnu** | **PathScale** | **PGI** | **Digital Mars** | **Watcom** | **Codeplay** |
| ------------------------------------------------------- | :-----------: | :---------: | :-------: | :-----: | :-----------: | :-----: | :------------------: | :--------: | :---------: |
| Function inlining                                       |       X       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      X      |
| Constant folding                                        |       X       |      X      |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| Constant propagation                                    |       X       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      X      |
| Pointer elimination                                     |       X       |      X      |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| Common subexpression elimin, integer                    |       X       |     (X)     |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| Common subexpression elimin,  float                     |       X       |      -      |     X     |    X    |       X       |    X    |        -         |        X        |      X      |
| Register variables, integer                             |       X       |      X      |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| Register variables, float                               |       X       |      -      |     X     |    X    |       X       |    X    |          -           |        X        |      X      |
| Live range analysis                                     |       X       |      X      |     X     |    X    |       X       |    X    |          X          |        X        |      X      |
| Join identical branches                                 |       X       |      -      |     -     |    X    |       -       |    -    |          -           |        X        |      -      |
| Eliminate jumps                                         |       X       |      X      |     X     |    X    |       X       |    X    |          -           |        X        |      X      |
| Eliminate branches                                      |       X       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      -      |
| Remove branch that is always true/false                 |       X       |      -      |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| Loop unrolling                                          |       X       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      X      |
| Loop invariant code motion                              |       X       |      -      |     X     |    X    |       X       |    X    |          X          |        X        |      X      |
| Induction variables for array elements                  |       X       |      X      |     X     |    X    |       X       |    X    |          X          |        X        |      X      |
| Induction variables for other integer expressions       |       X       |      -      |     X     |    X    |       X       |    -    |        X         |        X        |      X      |
| Induction variables for float expressions               |       -       |      -      |     -     |    -    |       -       |    -    |          -           |     -      |      -      |
| Automatic vectorization                                 |       -       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      X      |
| Devirtualization                                        |       -       |      -      |     -     |    X    |       -       |    -    |        -         |     -      |      -      |
| Profile-guided optimization                             |       X       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      -      |
| Whole program optimization                              |       X       |      -      |     X     |    X    |       X       |    -    |        -         |     -      |      -      |
|                                                         |               |             |           |         |               |         |                  |            |             |
| **Integer algebra reductions:**                         |               |             |           |         |               |         |                  |            |             |
| `a+b = b+a`                                             |       X       |     (X)     |     X     |    X    |       X       |    X    |          -           |        X        |      X      |
| `a*b = b*a`                                             |       X       |     (X)     |     X     |    X    |       X       |    X    |        -         |        X        |      X      |
| `a+b+c = a+(b+c)`                                       |       X       |      -      |     X     |    X    |       -       |    -    |        X         |        X        |      -      |
| `a+b+c = c+a+b`                                         |       X       |      -      |     -     |    X    |       -       |    -    |          -           |     -      |      -      |
| `a+b+c+d = (a+b)+(c+d)`                                 |       -       |      -      |     X     |    X    |       -       |    -    |          -           |     -      |      -      |
| `a*b+a*c = a*(b+c)`                                     |       X       |      -      |     X     |    X    |       X       |    -    |          -           |     -      |      X      |
| `a*x*x*x+b*x*x+c*x+d = <br>((a*x+b)*x+c)*x+d</br>`      |       X       |      -      |     X     |    X    |       X       |    -    |        X         |        X        |      X      |
| `X*X*X*X*X*X=((X<sup>2</sup>)<sup>2</sup>)<sup>2</sup>` |       -       |      -      |     -     |    X    |       -       |    -    |        -         |     -      |      -      |
| `a+a+a+a=a*4`                                           |       X       |      -      |     X     |    X    |       -       |    -    |          -           |     -      |      X      |
| `-(-a)=a`                                               |       X       |      -      |     X     |    X    |       X       |    X    |        X         |        X        |      -      |
| `a-(-b)=a+b`                                            |       X       |      -      |     X     |    X    |       X       |    X    |        -         |        X        |      -      |
| `a-a = 0`                                               |       X       |      -      |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| `a+0 = a`                                               |       X       |      X      |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| `a*0 = 0`                                               |       X       |      X      |     X     |    X    |       X       |    X    |        X         |     -      |      X      |
| `a*1 = a`                                               |       X       |      X      |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| `(-a)*(-b) = a*b`                                       |       X       |      -      |     X     |    X    |       X       |    -    |        -         |     -      |      -      |
| `a/a = 1`                                               |       -       |      -      |     -     |    -    |       X       |    -    |        -         |     -      |      X      |
| `a/1 = a`                                               |       X       |      X      |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| `0/a = 0`                                               |       -       |      -      |     -     |    X    |       X       |    -    |        -         |        X        |      X      |
| `(-a == -b) = (a == b)`                                 |       -       |      -      |     -     |    X    |       X       |    -    |          -           |     -      |      -      |
| `(a-c == b+c) = (a == b)`                               |       -       |      -      |     -     |    -    |       X       |    -    |          -           |     -      |      -      |
| `!(a < b) = (a >= b)`                                   |       X       |      X      |     X     |    X    |       X       |    X    |          X          |        X        |      X      |
| `(a<b && b<c && a<c) = (a<b && b<c)`                    |       -       |      -      |     -     |    -    |       -       |    -    |        -         |     -      |      -      |
| Multiply by constant = shift and add                    |       X       |      X      |     X     |    X    |       -       |    X    |          X          |        X        |      -      |
| Divide by constant = multiply and shift                 |       X       |      -      |     X     |    X    |       X       |   (-)   |        X         |     -      |      -      |
|                                                         |               |             |           |         |               |         |                  |            |             |
| **Floating point algebra reductions:**                  |               |             |           |         |               |         |                      |            |             |
| `a+b = b+a`                                             |       X       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      X      |
| `a*b = b*a`                                             |       X       |      -      |     X     |    X    |       X       |    X    |        -         |     -      |      X      |
| `a+b+c = a+(b+c)`                                       |       X       |      -      |     X     |    X    |       -       |    -    |          -           |     -      |      -      |
| `(a+b)+c = a+(b+c)`                                     |       -       |      -      |     X     |    X    |       -       |    -    |          -           |     -      |      -      |
| `a*b*c = a*(b*c)`                                       |       X       |      -      |     X     |    -    |       -       |    -    |        -         |     -      |      -      |
| `a+b+c+d = (a+b)+(c+d)`                                 |       -       |      -      |     -     |    X    |       -       |    -    |          -           |     -      |      -      |
| `a*b+a*c = a*(b+c)`                                     |       X       |      -      |     -     |    -    |       X       |    -    |          -           |     -      |      -      |
| `a*x*x*x+b*x*x+c*x+d = <br>((a*x+b)*x+c)*x+d</br>`      |       X       |      -      |     X     |    X    |       X       |    -    |        -         |        -        |      -      |
| `X*X*X*X*X*X=((X<sup>2</sup>)<sup>2</sup>)<sup>2</sup>` |       -       |      -      |     -     |    X    |       -       |    -    |        -         |     -      |      -      |
| `a+a+a+a=a*4`                                           |       X       |      -      |     X     |    X    |       -       |    -    |          -           |     -      |      -      |
| `-(-a)=a`                                               |       -       |      -      |     X     |    X    |       X       |    X    |        X         |        X        |      -      |
| `a-(-b)=a+b`                                            |       -       |      -      |     -     |    X    |       X       |    X    |        -         |        X        |      -      |
| `a+0 = a`                                               |       X       |      -      |     X     |    X    |       X       |    X    |        X         |        X        |      -      |
| `a*0 = 0`                                               |       -       |      -      |     X     |    X    |       X       |    X    |        -         |        X        |      X      |
| `a*1 = a`                                               |       X       |      -      |     X     |    X    |       X       |    X    |        X         |     -      |      X      |
| `(-a)*(-b) = a*b`                                       |       -       |      -      |     -     |    X    |       X       |    X    |        -         |     -      |      -      |
| `a/a = 1`                                               |       -       |      -      |     -     |    -    |       X       |    -    |        -         |     -      |      X      |
| `a/1 = a`                                               |       X       |      -      |     X     |    X    |       X       |    -    |        X         |     -      |      -      |
| `0/a = 0`                                               |       -       |      -      |     -     |    X    |       X       |    -    |        -         |        X        |      X      |
| `(-a == -b) = (a == b)`                                 |       -       |      -      |     -     |    X    |       X       |    -    |          -           |     -      |      -      |
| `(-a > -b) = (a < b)`                                   |       -       |      -      |     X     |    X    |       -       |    -    |        -         |     -      |      X      |
| Divide by constant = multiply by reciprocal             |       X       |      X      |     -     |    X    |       X       |    -    |        -         |        X        |      -      |
|                                                         |               |             |           |         |               |         |                  |            |             |
| **Boolean algebra reductions:**                         |               |             |           |         |               |         |                      |            |             |
| `!(!a) = a`                                             |       X       |      -      |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| `(a&&b)\|\|(a&&c) = a&&(b\|\|c)`                        |       X       |      -      |     X     |    X    |       X       |    -    |        -         |     -      |      -      |
| `!a && !b = !(a\|\|b)`                                  |       X       |      X      |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| `a && !a = false`,`a \|\| !b = true`                    |       X       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      -      |
| `a && true = a`,`a \|\| false = a`                      |       X       |      X      |     X     |    X    |       X       |    X    |        X         |        X        |      -      |
| `a && false = false`,`a \|\| true = true`               |       X       |      -      |     X     |    X    |       X       |    X    |          X          |        X        |      -      |
| `a && a = a`                                            |       X       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      -      |
| `(a&&b) \|\| (a&&!b) = a`                               |       X       |      -      |     -     |    X    |       X       |    -    |          -           |     -      |      -      |
| `(a&&b) \|\| (!a&&c) = a ? b : c`                       |       X       |      -      |     X     |    X    |       -       |    -    |          -           |     -      |      -      |
| `(a&&b) \|\| (!a&&c) \|\| (b&&c) = a ? b : c`           |       X       |      -      |     -     |    X    |       -       |    -    |          -           |     -      |      -      |
| `(a&&b) \|\| (a&&b&&c) = a&&b`                          |       X       |      -      |     -     |    X    |       X       |    -    |        -         |     -      |      -      |
| `(a&&b) \|\| (a&&c) \|\| (a&&b&&c) = a&&(b\|\|c)`       |       X       |      -      |     -     |    X    |       X       |    -    |        -         |     -      |      -      |
| `(a&&!b) \|\| (!a&&b) = a XOR b`                        |       -       |      -      |     -     |    -    |       -       |    -    |          -           |     -      |      -      |
|                                                         |               |             |           |         |               |         |                  |            |             |
| **Bit vector algebra reductions:**                      |               |             |           |         |               |         |                  |            |             |
| `~(~a) = a`                                             |       X       |      -      |     X     |    X    |       X       |    X    |        X         |     -      |      -      |
| `(a&b)\|(a&c) = a&(b\|c)`                               |       X       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      X      |
| `(a\|b)&(a\|c) = a\|(b&c)`                              |       X       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      X      |
| `~a & ~b = ~(a \| b)`                                   |       -       |      -      |     X     |    X    |       X       |    X    |          -           |     -      |      -      |
| `a & a = a`                                             |       X       |      -      |     -     |    X    |       X       |    X    |        -         |     -      |      X      |
| `a & ~a = 0`                                            |       -       |      -      |     -     |    X    |       X       |    X    |        -         |     -      |      -      |
| `a & -1 = a`,`a \| 0 = a`                               |       X       |      -      |     X     |    X    |       X       |    X    |        X         |        X        |      X      |
| `a & 0 = 0`,`a \| -1 = -1`                              |       X       |      -      |     X     |    X    |       X       |    X    |          X          |        X        |      X      |
| `(a&b) \| (~a&c) \| (b&c) = (a&b) \| (~a&c)`            |       -       |      -      |     -     |    -    |       -       |    -    |          -           |     -      |      -      |
| `a&b&c&d = (a&b)&(c&d)`                                 |       -       |      -      |     -     |    X    |       -       |    -    |        -         |     -      |      -      |
| `a ^ 0 = a`                                             |       X       |      X      |     X     |    X    |       X       |    -    |        X         |        X        |      X      |
| `a ^ -1 = ~a`                                           |       X       |      -      |     X     |    X    |       X       |    -    |        X         |        X        |      -      |
| `a ^ a = 0`                                             |       X       |      -      |     X     |    X    |       X       |    X    |        -         |        X        |      X      |
| `a ^ ~a = -1`                                           |       -       |      -      |     -     |    X    |       X       |    X    |        -         |     -      |      -      |
| `(a&~b) \| (~a&b) = a ^ b`                              |       -       |      -      |     -     |    -    |       -       |    -    |          -           |     -      |      -      |
| `~a ^ ~b = a ^ b`                                       |       -       |      -      |     -     |    X    |       X       |    -    |        -         |     -      |      -      |
| `a<<b<<c = a<<(b+c)`                                    |       X       |      -      |     X     |    X    |       X       |    -    |        -         |     X     |      X      |
|                                                         |               |             |           |         |               |         |                  |            |             |
| **Integer XMM (vector) reductions:**                    |               |             |           |         |               |         |                  |            |             |
| Common subexpression elimination                        |       X       |    n.a.     |     X     |    X    |       X       |    -    |       n.a.       |    n.a.     |      X      |
| Constant folding                                        |       -       |    n.a.     |     -     |    X    |       -       |    -    |        n.a.        |    n.a.     |      -      |
| `a+b = b+a`, `a*b = b*a`                                |       -       |    n.a.     |     -     |    X    |       -       |    -    |       n.a.       |    n.a.     |      X      |
| `(a+b)+c = a+(b+c)`                                     |       -       |    n.a.     |     -     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a*b+a*c = a*(b+c)`                                     |       -       |    n.a.     |     -     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `X*X*X*X*X*X=((X<sup>2</sup>)<sup>2</sup>)<sup>2</sup>` |       -       |    n.a.     |     -     |    -    |       -       |    -    |       n.a.       |    n.a.    |      -      |
| `a+a+a+a = a*4`                                         |       -       |    n.a.     |     -     |    -    |       -       |    -    |        n.a.        |    n.a.     |      -      |
| `-(-a) = a`                                             |       -       |    n.a.     |     -     |    -    |       -       |    -    |        n.a.        |    n.a.     |      -      |
| `a-a = 0`                                               |       -       |    n.a.     |     X     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a+0 = a`                                               |       -       |    n.a.     |     -     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a*0 = 0`                                               |       -       |    n.a.     |     -     |    X    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a*1 = a`                                               |       -       |    n.a.     |     -     |    X    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `(-a)*(-b) = a*b`                                       |       -       |    n.a.     |     -     |    -    |       -       |    -    |        n.a.        |    n.a.     |      -      |
| `!(a < b) = (a >= b)`                                   |       -       |    n.a.     |     -     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |
|                                                         |               |             |           |         |               |         |                  |            |             |
| **Floating point XMM (vector) reductions:**             |               |             |           |         |               |         |                  |            |             |
| `a+b = b+a`, `a*b = b*a`                                |       X       |    n.a.     |     -     |    X    |       -       |    -    |       n.a.       |    n.a.     |      X      |
| `(a+b)+c = a+(b+c)`                                     |       -       |    n.a.     |     -     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a*b+a*c = a*(b+c)`                                     |       -       |    n.a.     |     -     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `-(-a) = a`                                             |       -       |    n.a.     |     -     |    -    |       -       |    -    |        n.a.        |    n.a.     |      -      |
| `a-a = 0`                                               |       -       |    n.a.     |     -     |    X    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a+0 = a`                                               |       -       |    n.a.     |     X     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a*0 = 0`                                               |       -       |    n.a.     |     X     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a*1 = a`                                               |       -       |    n.a.     |     -     |    X    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a/1 = a`                                               |       -       |    n.a.     |     -     |    X    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `0/a = 0`                                               |       -       |    n.a.     |     X     |    X    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| Divide by constant = multiply by reciprocal             |       -       |    n.a.     |     -     |    -    |       -       |    -    |       n.a.       |    n.a.    |      -      |
|                                                         |               |             |           |         |               |         |                  |            |             |
| **Boolean XMM (vector) reductions:**                    |               |             |           |         |               |         |                  |            |             |
| `~(~a) = a`                                             |       -       |    n.a.     |     -     |    -    |       -       |    -    |        n.a.        |    n.a.     |      -      |
| `(a&b)\|(a&c) = a&(b\|c)`                               |       -       |    n.a.     |     -     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a & a = a`, `a \| a = a`                               |       -       |    n.a.     |     X     |    X    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a & ~a = 0`                                            |       -       |    n.a.     |     -     |    X    |       -       |    -    |        n.a.        |    n.a.     |      -      |
| `a & -1 = a`, `a \| 0 = a`                              |       -       |    n.a.     |     -     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |
| `a & 0 = 0`                                             |       -       |    n.a.     |     -     |    X    |       -       |    -    |        n.a.        |    n.a.     |      -      |
| `a \| -1 = -1`                                          |       -       |    n.a.     |     -     |    -    |       -       |    -    |        n.a.        |    n.a.     |      -      |
| `a ^ a = 0`                                             |       -       |    n.a.     |     X     |    X    |       -       |    -    |        n.a.        |    n.a.     |      -      |
| `andnot(a,a) = 0`                                       |       -       |    n.a.     |     -     |    X    |       -       |    -    |        n.a.        |    n.a.     |      -      |
| `a<<b<<c = a<<(b+c)`                                    |       -       |    n.a.     |     -     |    -    |       -       |    -    |       n.a.       |    n.a.     |      -      |

**Tabel 8.1. Comparison of optimizations in different C++ compilers**
</center>


测试中所有相关的优化选项都被打开，包括放宽浮点精度。被测试的编译器版本如下：
1. Microsoft C++ Compiler v. 14.00 for 80x86 / x64 (Visual Studio 2005).
2. Borland C++ 5.82 (Embarcadero/CodeGear/Borland C++ Builder 5, 2009).
3. Intel C++ Compiler v. 11.1 for IA-32/Intel64, 2009.
4. Gnu C++ v. 4.1.0, 2006 (Red Hat).
5. PathScale C++ v. 3.1, 2007.
6. PGI C++ v. 7.1-4, 2008.
7.  Digital Mars Compiler v. 8.42n, 2004.
8. Open Watcom C/C++ v. 1.4, 2005.
9. Codeplay VectorC v. 2.1.7, 2004.

没有发现*Microsoft*、*Intel*、*Gnu*和*PathScale*编译器的32位和64位代码的优化功能有任何差异。
